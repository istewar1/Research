{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ***k-NN and Decision Tree on Wisconsin Cancer Dataset***\n",
    "## *Class*: COSC528 - Project 3\n",
    "### *Author*: Ian R. Stewart\n",
    "### *Due Date*: November 6, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "savePath = '/Users/i6o/Research/COSC 528/Project 3/Figures/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample code number</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
       "0             1000025                5                        1   \n",
       "\n",
       "   Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "0                         1                  1                            2   \n",
       "\n",
       "  Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0           1                3                1        1      2  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading data\n",
    "features = ['Sample code number','Clump Thickness','Uniformity of Cell Size','Uniformity of Cell Shape','Marginal Adhesion','Single Epithelial Cell Size','Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses','Class']\n",
    "df = pd.read_csv('breast-cancer-wisconsin.data',names=features)\n",
    "'''\n",
    "------------------------------------------\n",
    "     Details for DataFrame Features\n",
    "------------------------------------------\n",
    "1. Sample code number: id number \n",
    "2. Clump Thickness: 1 – 10\n",
    "3. Uniformity of Cell Size: 1 – 10 \n",
    "4. Uniformity of Cell Shape: 1 – 10 \n",
    "5. Marginal Adhesion: 1 – 10\n",
    "6. Single Epithelial Cell Size: 1 – 10 \n",
    "7. Bare Nuclei: 1 – 10\n",
    "8. Bland Chromatin: 1 – 10\n",
    "9. Normal Nucleoli: 1 – 10\n",
    "10. Mitoses: 1 – 10\n",
    "11. Class: (2 for benign, 4 for malignant)\n",
    "'''\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(699, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sample code number              int64\n",
       "Clump Thickness                 int64\n",
       "Uniformity of Cell Size         int64\n",
       "Uniformity of Cell Shape        int64\n",
       "Marginal Adhesion               int64\n",
       "Single Epithelial Cell Size     int64\n",
       "Bare Nuclei                    object\n",
       "Bland Chromatin                 int64\n",
       "Normal Nucleoli                 int64\n",
       "Mitoses                         int64\n",
       "Class                           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df.shape\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sample code number             int64\n",
       "Clump Thickness                int64\n",
       "Uniformity of Cell Size        int64\n",
       "Uniformity of Cell Shape       int64\n",
       "Marginal Adhesion              int64\n",
       "Single Epithelial Cell Size    int64\n",
       "Bare Nuclei                    int64\n",
       "Bland Chromatin                int64\n",
       "Normal Nucleoli                int64\n",
       "Mitoses                        int64\n",
       "Class                          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping rows with '?' values in Bare Nuclei feature.\n",
    "df['Bare Nuclei'] = df['Bare Nuclei'].astype(str)\n",
    "count=0;indexes=[]\n",
    "for i in df['Bare Nuclei']:\n",
    "    try:\n",
    "        j = float(i)\n",
    "    except:\n",
    "        indexes.append(count)\n",
    "    count+=1\n",
    "print len(indexes)\n",
    "df = df.drop(indexes)\n",
    "df['Bare Nuclei'] = df['Bare Nuclei'].astype(int)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df[features[1::]],hue='Class',palette='coolwarm')\n",
    "#plt.savefig(savePath+'full_pairplot.png',dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating function to split data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(data_x,data_y,n):\n",
    "    '''\n",
    "    Description: Splits <data> variable into four random \n",
    "        parts based on <n> percentage of data for training \n",
    "        set.\n",
    "    \n",
    "    :param data_x {array} : x data to split,train,predict\n",
    "    :param data_y {array} : y data to split,train,predict\n",
    "    :param n      {float} : percentage of data to split\n",
    "    \n",
    "    :returns {6}: (x_train,x_test,y_train,y_test) ;     \n",
    "        x_train = training set for <x> parameter\n",
    "        x_test  = test set for <x> parameter\n",
    "        y_train = training set for <y> paramter\n",
    "        y_test  = test set for <y> parameter\n",
    "        i_train = indexes of training set split\n",
    "        i_test  = indexes of test set split\n",
    "    \n",
    "    e.g. x_tr,x,y_tr,y,i_tr,i_test=test_split(data,data_to_predict,40)\n",
    "    '''\n",
    "    data_x = np.asarray(data_x)\n",
    "    length_test = int(round(len(data_x)*(n/100.)))\n",
    "    # Create random integers between two numbers with no repeats\n",
    "    train_list = random.sample(range(0,len(data_x)), length_test)\n",
    "    train_list.sort()\n",
    "    test_list = np.arange(0,len(data_x))\n",
    "    test_list = np.delete(test_list,train_list)\n",
    "    data_y = np.array(data_y)\n",
    "    x_train,y_train = np.array(data_x[train_list]),np.array(data_y[train_list])\n",
    "    x_test,y_test   = np.array(data_x[test_list]),np.array(data_y[test_list])\n",
    "    \n",
    "    return (x_train,x_test,y_train,y_test,train_list,list(test_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not using *Sample Code No.* in analysis. Using the *Class* feature as the predictor parameter and the other features (minus the *Sample Code No.*) as the estimating parameters. Also, *z*-standardizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(683, 8) (683,)\n"
     ]
    }
   ],
   "source": [
    "df_standardized = (df-df.mean())/df.std()\n",
    "data_x = df_standardized.iloc[:,1:-2]\n",
    "data_y = df.iloc[:,-1]\n",
    "print data_x.shape,data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test,train_list,test_check = test_split(data_x,data_y,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shapes: \n",
      "\t{ Data:(410, 8),\tPredictor:(410,) }\n",
      "Test set shapes: \n",
      "\t{ Data:(273, 8),\tPredictor:(273,) }\n"
     ]
    }
   ],
   "source": [
    "# Checking split shapes\n",
    "print 'Training set shapes: \\n\\t{ Data:%s,\\tPredictor:%s }'%(x_train.shape,y_train.shape)\n",
    "print 'Test set shapes: \\n\\t{ Data:%s,\\tPredictor:%s }'%(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.0) Data Analysis**: *k*-**NN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(data_x,data_y,n):\n",
    "    data_x = np.asarray(data_x)\n",
    "    length_test = int(round(len(data_x)*(n/100.)))\n",
    "    # Create random integers between two numbers with no repeats\n",
    "    train_list = random.sample(range(0,len(data_x)), length_test)\n",
    "    train_list.sort()\n",
    "    test_list = np.arange(0,len(data_x))\n",
    "    test_list = np.delete(test_list,train_list)\n",
    "    data_y = np.array(data_y)\n",
    "    x_train,y_train = np.array(data_x[train_list]),np.array(data_y[train_list])\n",
    "    x_test,y_test   = np.array(data_x[test_list]),np.array(data_y[test_list])\n",
    "    \n",
    "    return (x_train,x_test,y_train,y_test,train_list,list(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test,train_list,test_list = test_split(data_x,data_y,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def getNeighbors(x_training,x_test,y_training,y_test,k=3):\n",
    "    y_prediction = {}; dist = []\n",
    "    counter = 0; y_pred = []\n",
    "    for i in x_test:\n",
    "        dist = []\n",
    "        for j in x_training:\n",
    "            dist.append(sum(np.absolute(i-j)))\n",
    "        dist_sorted = np.array(sorted(dist))\n",
    "\n",
    "        closest_indexes = []\n",
    "        for value in range(k):\n",
    "            index = np.where(dist==dist_sorted[value])[0][0]\n",
    "            closest_indexes.append(index)\n",
    "            \n",
    "        classes = np.array(y_training)[closest_indexes]\n",
    "        class_chosen = Counter(classes)\n",
    "        predicted_class = class_chosen.keys()[np.argmax(class_chosen.values())]\n",
    "        y_prediction[counter] = predicted_class\n",
    "        y_pred.append(predicted_class)\n",
    "        counter+=1\n",
    "        \n",
    "    return y_prediction,y_pred\n",
    "\n",
    "def confusion_matrix(y_predicted,y_true,prints=True):\n",
    "    TN=0;FN=0;TP=0;FP=0\n",
    "    for i in range(len(y_predicted)):\n",
    "        y_pred0 = y_predicted[i]\n",
    "        y_true0 = y_true[i]\n",
    "        if y_pred0 == y_true0:\n",
    "            if y_pred0==4:\n",
    "                TP+=1\n",
    "            else:\n",
    "                TN+=1\n",
    "        else:\n",
    "            if y_pred0 == 2:\n",
    "                FN+=1\n",
    "            if y_pred0 == 4:\n",
    "                FP+=1\n",
    "    if prints:\n",
    "        print '======== CONFUSION MATRIX ========'\n",
    "        print '\\t\\tPREDICTED CLASS\\n\\t\\t---------------\\nTRUE CLASS  |  Benign\\tMalignant\\n  Benign    |\\t%i\\t%i\\n  Malignant |\\t%i\\t%i'%(TN,FP,FN,TP)\n",
    "        print '=================================='\n",
    "    return TN,FN,TP,FP\n",
    "            \n",
    "def getMetrics(TN,FN,TP,FP,prints=True):\n",
    "    TN,FN,TP,FP=float(TN),float(FN),float(TP),float(FP)\n",
    "    Acc = (TN+TP)/(TN+TP+FN+FP)\n",
    "    TPR = TP/(TP+FN)\n",
    "    PPV = TP/(TP+FP)\n",
    "    TNR = TN/(TN+FP)\n",
    "    F1  = (2*PPV*TPR)/(PPV+TPR)\n",
    "    if prints:\n",
    "        metrics = [Acc,TPR,PPV,TNR,F1]\n",
    "        labels = ['Acc.','TPR','PPV','TNR','F1']\n",
    "        print '====== Performance Metrics ======'\n",
    "        for i in range(len(labels)):\n",
    "            print '\\t%s\\t: %.4f'%(labels[i],metrics[i])\n",
    "        print '================================='\n",
    "    return Acc,TPR,PPV,TNR,F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dict,y_pred = getNeighbors(x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== CONFUSION MATRIX ========\n",
      "\t\tPREDICTED CLASS\n",
      "\t\t---------------\n",
      "TRUE CLASS  |  Benign\tMalignant\n",
      "  Benign    |\t219\t6\n",
      "  Malignant |\t5\t111\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "TN,FN,TP,FP = confusion_matrix(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Performance Metrics ======\n",
      "\tAcc.\t: 0.9677\n",
      "\tTPR\t: 0.9569\n",
      "\tPPV\t: 0.9487\n",
      "\tTNR\t: 0.9733\n",
      "\tF1\t: 0.9528\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "metrics= getMetrics(TN,FN,TP,FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Scikit-Learns KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[217   8]\n",
      " [  4 112]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          2       0.98      0.96      0.97       225\n",
      "          4       0.93      0.97      0.95       116\n",
      "\n",
      "avg / total       0.97      0.96      0.96       341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(x_train,y_train)\n",
    "pred = knn.predict(x_test)\n",
    "print confusion_matrix(y_test,pred)\n",
    "print '\\n'\n",
    "print classification_report(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,u'k (No. of Neighbors)')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a10ee3d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_rate = []\n",
    "for i in range(1,8):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(x_train,y_train)\n",
    "    pred_i = knn.predict(x_test)\n",
    "    error_rate.append(np.mean(pred_i!=y_test))\n",
    "plt.figure(dpi=80)\n",
    "plt.plot(error_rate,'bo--',linewidth=1,markerfacecolor='red',markersize=10,label='sklearn KNN')\n",
    "plt.grid(alpha=0.5)\n",
    "plt.legend(loc='upper right',fancybox=True,shadow=True)\n",
    "plt.ylabel('Error Rate');plt.xlabel('k (No. of Neighbors)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(data_x,data_y,n):\n",
    "    data_x = np.asarray(data_x)\n",
    "    length_test = int(round(len(data_x)*(n/100.)))\n",
    "    # Create random integers between two numbers with no repeats\n",
    "    train_list = random.sample(range(0,len(data_x)), length_test)\n",
    "    train_list.sort()\n",
    "    test_list = np.arange(0,len(data_x))\n",
    "    test_list = np.delete(test_list,train_list)\n",
    "    data_y = np.array(data_y)\n",
    "    x_train,y_train = np.array(data_x[train_list]),np.array(data_y[train_list])\n",
    "    x_test,y_test   = np.array(data_x[test_list]),np.array(data_y[test_list])\n",
    "    \n",
    "    return (x_train,x_test,y_train,y_test,train_list,list(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test,train_list,test_list = test_split(data_x,data_y,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def getNeighbors(x_training,x_test,y_training,y_test,k=3):\n",
    "    y_prediction = {}; dist = []\n",
    "    counter = 0; y_pred = []\n",
    "    for i in x_test:\n",
    "        dist = []\n",
    "        for j in x_training:\n",
    "            dist.append(sum(np.absolute(i-j)))\n",
    "        dist_sorted = np.array(sorted(dist))\n",
    "\n",
    "        closest_indexes = []\n",
    "        for value in range(k):\n",
    "            index = np.where(dist==dist_sorted[value])[0][0]\n",
    "            closest_indexes.append(index)\n",
    "            \n",
    "        classes = np.array(y_training)[closest_indexes]\n",
    "        class_chosen = Counter(classes)\n",
    "        predicted_class = class_chosen.keys()[np.argmax(class_chosen.values())]\n",
    "        y_prediction[counter] = predicted_class\n",
    "        y_pred.append(predicted_class)\n",
    "        counter+=1\n",
    "        \n",
    "    return y_prediction,y_pred\n",
    "\n",
    "def confusion_matrix(y_predicted,y_true,prints=True):\n",
    "    TN=0;FN=0;TP=0;FP=0\n",
    "    for i in range(len(y_predicted)):\n",
    "        y_pred0 = y_predicted[i]\n",
    "        y_true0 = y_true[i]\n",
    "        if y_pred0 == y_true0:\n",
    "            if y_pred0==4:\n",
    "                TP+=1\n",
    "            else:\n",
    "                TN+=1\n",
    "        else:\n",
    "            if y_pred0 == 2:\n",
    "                FN+=1\n",
    "            if y_pred0 == 4:\n",
    "                FP+=1\n",
    "    if prints:\n",
    "        print '======== CONFUSION MATRIX ========'\n",
    "        print '\\t\\tPREDICTED CLASS\\n\\t\\t---------------\\nTRUE CLASS  |  Benign\\tMalignant\\n  Benign    |\\t%i\\t%i\\n  Malignant |\\t%i\\t%i'%(TN,FP,FN,TP)\n",
    "        print '=================================='\n",
    "    return TN,FN,TP,FP\n",
    "            \n",
    "def getMetrics(TN,FN,TP,FP,prints=True):\n",
    "    TN,FN,TP,FP=float(TN),float(FN),float(TP),float(FP)\n",
    "    Acc = (TN+TP)/(TN+TP+FN+FP)\n",
    "    TPR = TP/(TP+FN)\n",
    "    PPV = TP/(TP+FP)\n",
    "    TNR = TN/(TN+FP)\n",
    "    F1  = (2*PPV*TPR)/(PPV+TPR)\n",
    "    if prints:\n",
    "        labels = ['Acc.','TPR','PPV','TNR','F1']\n",
    "        print '====== Performance Metrics ======'\n",
    "        for i in range(len(labels)):\n",
    "            print '\\t%s\\t: %.4f'%(labels[i],metrics[i])\n",
    "        print '================================='\n",
    "    return Acc,TPR,PPV,TNR,F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choosing *k*=3 for optimal nearest-neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dict,y_pred = getNeighbors(x_train,x_test,y_train,y_test,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== CONFUSION MATRIX ========\n",
      "\t\tPREDICTED CLASS\n",
      "\t\t---------------\n",
      "TRUE CLASS  |  Benign\tMalignant\n",
      "  Benign    |\t211\t4\n",
      "  Malignant |\t8\t118\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "TN,FN,TP,FP = confusion_matrix(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Performance Metrics ======\n",
      "\tAcc.\t: 0.9648\n",
      "\tTPR\t: 0.9365\n",
      "\tPPV\t: 0.9672\n",
      "\tTNR\t: 0.9814\n",
      "\tF1\t: 0.9516\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "metrics= getMetrics(TN,FN,TP,FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1) Data Analysis - Decision Tree Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decision_tree(object):\n",
    "    \n",
    "    def __init__(self,depth=2):\n",
    "        self.max_depth = depth\n",
    "    \n",
    "    def gini(self,features,classes):\n",
    "        gini_index = 0\n",
    "        for feature in features:\n",
    "            size=len(feature) ; score = 0.0\n",
    "            for class_val in classes:\n",
    "                score += ((feature[:,-1] == class_val).sum()/float(size))**2\n",
    "            gini_index += (1.0-score)*(float(size)/sum([len(feature) for feature in features]))\n",
    "        return gini_index\n",
    "    \n",
    "    def gini_score(self, groups, classes):\n",
    "        n_samples = sum([len(group) for group in groups])\n",
    "        gini = 0\n",
    "        for group in groups:\n",
    "            size = float(len(group))\n",
    "            if size == 0:\n",
    "                continue\n",
    "            score = 0.0\n",
    "            #print(size)\n",
    "            for class_val in classes:\n",
    "                #print(group.shape)\n",
    "                p = (group[:,-1] == class_val).sum() / size\n",
    "                #print(p)\n",
    "                score += p * p\n",
    "            gini += (1.0 - score) * (size / n_samples)\n",
    "            #print(gini)\n",
    "        return gini\n",
    "    \n",
    "    def entropy(self,data_y):\n",
    "        elements,counts = np.unique(data_y,return_counts=True)\n",
    "        en = []\n",
    "        for i in range(len(elements)):\n",
    "            en.append( (-counts[i]/sum(counts))*float(np.log2(counts[i]/sum(counts))) )\n",
    "        return np.sum(en)\n",
    "    \n",
    "    def tree_split(self, feature, value, data):\n",
    "        data_left = np.array([]).reshape(0,self.data.shape[1])\n",
    "        data_right = np.array([]).reshape(0,self.data.shape[1])\n",
    "        for i in data:\n",
    "            if i[feature] <= value:\n",
    "                data_left = np.vstack((data_left,i))\n",
    "            if i[feature] > value:\n",
    "                data_right = np.vstack((data_right,i))\n",
    "        return data_left, data_right\n",
    "\n",
    "    def choose_split(self, data):\n",
    "        classes = np.unique(self.data[:,-1])\n",
    "        best_feat = 999;best_val = 999;best_score = 999;best_groups = None\n",
    "        for feat in range(self.data.shape[1]-1):\n",
    "            for i in data:\n",
    "                features = self.tree_split(feat,i[feat],self.data)\n",
    "                if self.cost_function=='gini':\n",
    "                    value = self.gini_score(np.array(features), classes)\n",
    "                if self.cost_function=='entropy':\n",
    "                    value = self.entropy(self.data_y)\n",
    "                if value < best_score:\n",
    "                    best_feat = feat\n",
    "                    best_val = i[feat]\n",
    "                    best_score = value\n",
    "                    best_groups = groups\n",
    "        output = {}\n",
    "        output['feat'] = best_feat\n",
    "        output['val'] = best_val\n",
    "        output['groups'] = best_groups\n",
    "        return output\n",
    "    \n",
    "    def split_attribute(self,leaf,depth):\n",
    "        left_leaf, right_leaf = leaf['groups']; del(leaf['groups'])\n",
    "        if depth >= self.max_depth:\n",
    "            leaf['left'] = self.terminal_leaf(left_leaf)\n",
    "            leaf['right'] = self.terminal_leaf(right_leaf)\n",
    "            return\n",
    "            \n",
    "    def predict_sample(self, node, sample):\n",
    "        if sample[node['feat']] < node['val']:\n",
    "            if isinstance(node['left'],dict):\n",
    "                return self.predict_sample(node['left'],sample)\n",
    "            else:\n",
    "                return node['left']\n",
    "        else:\n",
    "            if isinstance(node['right'],dict):\n",
    "                return self.predict_sample(node['right'],sample)\n",
    "            else:\n",
    "                return node['right']\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        self.prediction = np.array([])\n",
    "        for i in X_test:\n",
    "            self.prediction = np.append(self.prediction,self.predict_sample(self.root,i))\n",
    "        return self.prediction\n",
    "    ''''''\n",
    "    def best_split(self, Xy):\n",
    "        classes = np.unique(Xy[:,-1])\n",
    "        best_score = 999\n",
    "        for feat in range(Xy.shape[1]-1):\n",
    "            for i in Xy:\n",
    "                groups = self.tree_split(feat, i[feat], Xy)\n",
    "                gini = self.gini_score(groups, classes)\n",
    "                if gini < best_score:\n",
    "                    best_feat = feat\n",
    "                    best_val = i[feat]\n",
    "                    best_score = gini\n",
    "                    best_groups = groups\n",
    "        output = {}\n",
    "        output['feat'] = best_feat\n",
    "        output['val'] = best_val\n",
    "        output['groups'] = best_groups\n",
    "        return output\n",
    "    \n",
    "    def terminal_node(self, group):\n",
    "        # errored out: couldn't np.unique(nothing) or something - doesn't happen all the time\n",
    "        #print(group[:,-1])\n",
    "        classes, counts = np.unique(group[:,-1],return_counts=True)\n",
    "        return classes[np.argmax(counts)]\n",
    "            \n",
    "    def split_branch(self, node, depth):\n",
    "        left_node, right_node = node['groups']\n",
    "        del(node['groups'])\n",
    "        if not isinstance(left_node,np.ndarray) or not isinstance(right_node,np.ndarray):\n",
    "            node['left'] = node['right'] = self.terminal_node(left_node + right_node)\n",
    "            return\n",
    "        if depth >= self.max_depth:\n",
    "            node['left'] = self.terminal_node(left_node)\n",
    "            node['right'] = self.terminal_node(right_node)\n",
    "            return\n",
    "    \n",
    "    def build_tree(self):\n",
    "        '''Recursively build tree, unclear if this is the correct way\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        self.root = self.best_split(self.data)\n",
    "        #print(self.root)\n",
    "        self.split_branch(self.root, 1) # i don't understand how this is working, pointed to node?\n",
    "        #print(self.root)\n",
    "        return self.root\n",
    "    \n",
    "    def train(self,data_x,data_y,cost):\n",
    "        self.cost_function = cost # entropy, gin, or misclassification error\n",
    "        self.data_x = data_x      # numeric values for feature data\n",
    "        self.data_y = data_y      # class values for feature data\n",
    "        self.data = np.column_stack((data_x,data_y)) # creating matrix for training set\n",
    "        self.build_tree()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = decision_tree()\n",
    "dt.train(data_x=X_train,data_y=y_train,cost='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decision_tree(object):\n",
    "    def __init__(self, max_depth,min_num_sample):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_num_sample = min_num_sample\n",
    "    \n",
    "    \n",
    "    def gini(self, groups, classes):\n",
    "        n_samples = sum([len(group) for group in groups])\n",
    "        gini = 0\n",
    "        for group in groups:\n",
    "            size = float(len(group))\n",
    "            if size == 0:\n",
    "                continue\n",
    "            score = 0.0\n",
    "            for class_val in classes:\n",
    "                score += np.power((group[:,-1] == class_val).sum() / size,2)\n",
    "            gini += (1.0-score)*(size/sum([len(group) for group in groups]))\n",
    "        return gini\n",
    "    \n",
    "    def tree_split(self, feat, val, data):\n",
    "        Xi_left = np.array([]).reshape(0,self.data.shape[1])\n",
    "        Xi_right = np.array([]).reshape(0,self.data.shape[1])\n",
    "        for i in self.data:\n",
    "            if i[feat] <= val:\n",
    "                Xi_left = np.vstack((Xi_left,i))\n",
    "            if i[feat] > val:\n",
    "                Xi_right = np.vstack((Xi_right,i))\n",
    "        return Xi_left, Xi_right\n",
    "    \n",
    "    def best_split(self, data):\n",
    "        classes = np.unique(self.data[:,-1])\n",
    "        best_score = 999\n",
    "        for feat in range(self.data.shape[1]-1):\n",
    "            for i in self.data:\n",
    "                groups = self.tree_split(feat, i[feat], self.data)\n",
    "                gini = self.gini(groups, classes)\n",
    "                if gini < best_score:\n",
    "                    best_feat = feat\n",
    "                    best_val = i[feat]\n",
    "                    best_score = gini\n",
    "                    best_groups = groups\n",
    "        output = {}\n",
    "        output['feat'] = best_feat\n",
    "        output['val'] = best_val\n",
    "        output['groups'] = best_groups\n",
    "        return output\n",
    "    \n",
    "    def terminal_node(self, group):\n",
    "        classes, counts = np.unique(group[:,-1],return_counts=True)\n",
    "        return classes[np.argmax(counts)]\n",
    "            \n",
    "    def split_branch(self, node, depth):\n",
    "        left_node, right_node = node['groups']\n",
    "        del(node['groups'])\n",
    "        if not isinstance(left_node,np.ndarray) or not isinstance(right_node,np.ndarray):\n",
    "            node['left'] = node['right'] = self.terminal_node(left_node + right_node)\n",
    "            return\n",
    "        if depth >= self.max_depth:\n",
    "            node['left'] = self.terminal_node(left_node)\n",
    "            node['right'] = self.terminal_node(right_node)\n",
    "            return\n",
    "        if len(left_node) <= self.min_num_sample:\n",
    "            node['left'] = self.terminal_node(left_node)\n",
    "        else:\n",
    "            node['left'] = self.best_split(left_node)\n",
    "            self.split_branch(node['left'], depth+1)\n",
    "        if len(right_node) <= self.min_num_sample:\n",
    "            node['right'] = self.terminal_node(right_node)\n",
    "        else:\n",
    "            node['right'] = self.best_split(right_node)\n",
    "            self.split_branch(node['right'], depth+1)\n",
    "    \n",
    "    def build_tree(self):\n",
    "        self.root = self.best_split(self.data)\n",
    "        self.split_branch(self.root, 1)\n",
    "        return self.root\n",
    "    \n",
    "    def train(self,data_x,data_y):\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.data = np.column_stack((data_x,data_y))\n",
    "        self.root = self.best_split(self.data)\n",
    "        self.split_branch(self.root, 1)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        self.y_pred = np.array([])\n",
    "        for i in X_test:\n",
    "            self.y_pred = np.append(self.y_pred,self.predict_sample(self.root,i))\n",
    "        return self.y_pred\n",
    "    \n",
    "    def predict_sample(self, node, sample):\n",
    "        if sample[node['feat']] < node['val']:\n",
    "            if isinstance(node['left'],dict):\n",
    "                return self.predict_sample(node['left'],sample)\n",
    "            else:\n",
    "                return node['left']\n",
    "        else:\n",
    "            if isinstance(node['right'],dict):\n",
    "                return self.predict_sample(node['right'],sample)\n",
    "            else:\n",
    "                return node['right']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = decision_tree(max_depth=2,min_num_sample=20)\n",
    "dt.train(X_train,y_train)\n",
    "my_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 2., 4., 4., 4., 4., 4., 2., 4., 2., 4., 2., 4., 2., 4., 2., 2.,\n",
       "       4., 2., 2., 4., 2., 2., 4., 4., 4., 4., 2., 4., 4., 2., 2., 2., 4.,\n",
       "       4., 2., 4., 2., 2., 2., 4., 2., 4., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 4., 4., 4., 4., 4., 2., 4., 2., 2., 2., 2., 4., 2., 2., 2.,\n",
       "       4., 4., 4., 4., 2., 2., 2., 2., 4., 4., 4., 2., 2., 4., 2., 2., 4.,\n",
       "       2., 4., 2., 4., 2., 4., 2., 4., 2., 4., 2., 4., 4., 4., 4., 2., 2.,\n",
       "       4., 4., 2., 4., 2., 2., 2., 2., 2., 4., 2., 2., 2., 4., 2., 4., 4.,\n",
       "       2., 4., 2., 2., 2., 4., 4., 2., 2., 2., 2., 2., 4., 4., 2., 2., 2.,\n",
       "       2., 2., 4., 2., 4., 2., 2., 4., 2., 2., 2., 2., 4., 2., 2., 2., 4.,\n",
       "       4., 2., 2., 4., 4., 4., 2., 2., 2., 4., 2., 4., 4., 2., 4., 2., 4.,\n",
       "       2.])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.root\n",
    "my_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
