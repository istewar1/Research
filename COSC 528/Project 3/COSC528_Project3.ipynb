{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ***k-NN and Decision Tree on Wisconsin Cancer Dataset***\n",
    "## *Class*: COSC528 - Project 3\n",
    "### *Author*: Ian R. Stewart\n",
    "### *Due Date*: November 6, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "savePath = '/Users/i6o/Research/COSC 528/Project 3/Figures/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample code number</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
       "0             1000025                5                        1   \n",
       "\n",
       "   Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "0                         1                  1                            2   \n",
       "\n",
       "  Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0           1                3                1        1      2  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading data\n",
    "features = ['Sample code number','Clump Thickness','Uniformity of Cell Size','Uniformity of Cell Shape','Marginal Adhesion','Single Epithelial Cell Size','Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses','Class']\n",
    "df = pd.read_csv('breast-cancer-wisconsin.data',names=features)\n",
    "'''\n",
    "------------------------------------------\n",
    "     Details for DataFrame Features\n",
    "------------------------------------------\n",
    "1. Sample code number: id number \n",
    "2. Clump Thickness: 1 – 10\n",
    "3. Uniformity of Cell Size: 1 – 10 \n",
    "4. Uniformity of Cell Shape: 1 – 10 \n",
    "5. Marginal Adhesion: 1 – 10\n",
    "6. Single Epithelial Cell Size: 1 – 10 \n",
    "7. Bare Nuclei: 1 – 10\n",
    "8. Bland Chromatin: 1 – 10\n",
    "9. Normal Nucleoli: 1 – 10\n",
    "10. Mitoses: 1 – 10\n",
    "11. Class: (2 for benign, 4 for malignant)\n",
    "'''\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(699, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sample code number              int64\n",
       "Clump Thickness                 int64\n",
       "Uniformity of Cell Size         int64\n",
       "Uniformity of Cell Shape        int64\n",
       "Marginal Adhesion               int64\n",
       "Single Epithelial Cell Size     int64\n",
       "Bare Nuclei                    object\n",
       "Bland Chromatin                 int64\n",
       "Normal Nucleoli                 int64\n",
       "Mitoses                         int64\n",
       "Class                           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df.shape\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sample code number             int64\n",
       "Clump Thickness                int64\n",
       "Uniformity of Cell Size        int64\n",
       "Uniformity of Cell Shape       int64\n",
       "Marginal Adhesion              int64\n",
       "Single Epithelial Cell Size    int64\n",
       "Bare Nuclei                    int64\n",
       "Bland Chromatin                int64\n",
       "Normal Nucleoli                int64\n",
       "Mitoses                        int64\n",
       "Class                          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping rows with '?' values in Bare Nuclei feature.\n",
    "df['Bare Nuclei'] = df['Bare Nuclei'].astype(str)\n",
    "count=0;indexes=[]\n",
    "for i in df['Bare Nuclei']:\n",
    "    try:\n",
    "        j = float(i)\n",
    "    except:\n",
    "        indexes.append(count)\n",
    "    count+=1\n",
    "print len(indexes)\n",
    "df = df.drop(indexes)\n",
    "df['Bare Nuclei'] = df['Bare Nuclei'].astype(int)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df[features[1::]],hue='Class',palette='coolwarm')\n",
    "#plt.savefig(savePath+'full_pairplot.png',dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating function to split data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(data_x,data_y,n):\n",
    "    '''\n",
    "    Description: Splits <data> variable into four random \n",
    "        parts based on <n> percentage of data for training \n",
    "        set.\n",
    "    \n",
    "    :param data_x {array} : x data to split,train,predict\n",
    "    :param data_y {array} : y data to split,train,predict\n",
    "    :param n      {float} : percentage of data to split\n",
    "    \n",
    "    :returns {6}: (x_train,x_test,y_train,y_test) ;     \n",
    "        x_train = training set for <x> parameter\n",
    "        x_test  = test set for <x> parameter\n",
    "        y_train = training set for <y> paramter\n",
    "        y_test  = test set for <y> parameter\n",
    "        i_train = indexes of training set split\n",
    "        i_test  = indexes of test set split\n",
    "    \n",
    "    e.g. x_tr,x,y_tr,y,i_tr,i_test=test_split(data,data_to_predict,40)\n",
    "    '''\n",
    "    data_x = np.asarray(data_x)\n",
    "    length_test = int(round(len(data_x)*(n/100.)))\n",
    "    # Create random integers between two numbers with no repeats\n",
    "    train_list = random.sample(range(0,len(data_x)), length_test)\n",
    "    train_list.sort()\n",
    "    test_list = np.arange(0,len(data_x))\n",
    "    test_list = np.delete(test_list,train_list)\n",
    "    data_y = np.array(data_y)\n",
    "    x_train,y_train = np.array(data_x[train_list]),np.array(data_y[train_list])\n",
    "    x_test,y_test   = np.array(data_x[test_list]),np.array(data_y[test_list])\n",
    "    \n",
    "    return (x_train,x_test,y_train,y_test,train_list,list(test_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not using *Sample Code No.* in analysis. Using the *Class* feature as the predictor parameter and the other features (minus the *Sample Code No.*) as the estimating parameters. Also, *z*-standardizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(683, 8) (683,)\n"
     ]
    }
   ],
   "source": [
    "df_standardized = (df-df.mean())/df.std()\n",
    "data_x = df_standardized.iloc[:,1:-2]\n",
    "data_y = df.iloc[:,-1]\n",
    "print data_x.shape,data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test,train_list,test_check = test_split(data_x,data_y,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shapes: \n",
      "\t{ Data:(410, 8),\tPredictor:(410,) }\n",
      "Test set shapes: \n",
      "\t{ Data:(273, 8),\tPredictor:(273,) }\n"
     ]
    }
   ],
   "source": [
    "# Checking split shapes\n",
    "print 'Training set shapes: \\n\\t{ Data:%s,\\tPredictor:%s }'%(x_train.shape,y_train.shape)\n",
    "print 'Test set shapes: \\n\\t{ Data:%s,\\tPredictor:%s }'%(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.0) Data Analysis**: *k*-**NN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(data_x,data_y,n):\n",
    "    data_x = np.asarray(data_x)\n",
    "    length_test = int(round(len(data_x)*(n/100.)))\n",
    "    # Create random integers between two numbers with no repeats\n",
    "    train_list = random.sample(range(0,len(data_x)), length_test)\n",
    "    train_list.sort()\n",
    "    test_list = np.arange(0,len(data_x))\n",
    "    test_list = np.delete(test_list,train_list)\n",
    "    data_y = np.array(data_y)\n",
    "    x_train,y_train = np.array(data_x[train_list]),np.array(data_y[train_list])\n",
    "    x_test,y_test   = np.array(data_x[test_list]),np.array(data_y[test_list])\n",
    "    \n",
    "    return (x_train,x_test,y_train,y_test,train_list,list(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test,train_list,test_list = test_split(data_x,data_y,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def getNeighbors(x_training,x_test,y_training,y_test,k=3):\n",
    "    y_prediction = {}; dist = []\n",
    "    counter = 0; y_pred = []\n",
    "    for i in x_test:\n",
    "        dist = []\n",
    "        for j in x_training:\n",
    "            dist.append(sum(np.absolute(i-j)))\n",
    "        dist_sorted = np.array(sorted(dist))\n",
    "\n",
    "        closest_indexes = []\n",
    "        for value in range(k):\n",
    "            index = np.where(dist==dist_sorted[value])[0][0]\n",
    "            closest_indexes.append(index)\n",
    "            \n",
    "        classes = np.array(y_training)[closest_indexes]\n",
    "        class_chosen = Counter(classes)\n",
    "        predicted_class = class_chosen.keys()[np.argmax(class_chosen.values())]\n",
    "        y_prediction[counter] = predicted_class\n",
    "        y_pred.append(predicted_class)\n",
    "        counter+=1\n",
    "        \n",
    "    return y_prediction,y_pred\n",
    "\n",
    "def confusion_matrix(y_predicted,y_true,prints=True):\n",
    "    TN=0;FN=0;TP=0;FP=0\n",
    "    for i in range(len(y_predicted)):\n",
    "        y_pred0 = y_predicted[i]\n",
    "        y_true0 = y_true[i]\n",
    "        if y_pred0 == y_true0:\n",
    "            if y_pred0==4:\n",
    "                TP+=1\n",
    "            else:\n",
    "                TN+=1\n",
    "        else:\n",
    "            if y_pred0 == 2:\n",
    "                FN+=1\n",
    "            if y_pred0 == 4:\n",
    "                FP+=1\n",
    "    if prints:\n",
    "        print '======== CONFUSION MATRIX ========'\n",
    "        print '\\t\\tPREDICTED CLASS\\n\\t\\t---------------\\nTRUE CLASS  |  Benign\\tMalignant\\n  Benign    |\\t%i\\t%i\\n  Malignant |\\t%i\\t%i'%(TN,FP,FN,TP)\n",
    "        print '=================================='\n",
    "    return TN,FN,TP,FP\n",
    "            \n",
    "def getMetrics(TN,FN,TP,FP,prints=True):\n",
    "    TN,FN,TP,FP=float(TN),float(FN),float(TP),float(FP)\n",
    "    Acc = (TN+TP)/(TN+TP+FN+FP)\n",
    "    TPR = TP/(TP+FN)\n",
    "    PPV = TP/(TP+FP)\n",
    "    TNR = TN/(TN+FP)\n",
    "    F1  = (2*PPV*TPR)/(PPV+TPR)\n",
    "    if prints:\n",
    "        metrics = [Acc,TPR,PPV,TNR,F1]\n",
    "        labels = ['Acc.','TPR','PPV','TNR','F1']\n",
    "        print '====== Performance Metrics ======'\n",
    "        for i in range(len(labels)):\n",
    "            print '\\t%s\\t: %.4f'%(labels[i],metrics[i])\n",
    "        print '================================='\n",
    "    return Acc,TPR,PPV,TNR,F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dict,y_pred = getNeighbors(x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== CONFUSION MATRIX ========\n",
      "\t\tPREDICTED CLASS\n",
      "\t\t---------------\n",
      "TRUE CLASS  |  Benign\tMalignant\n",
      "  Benign    |\t220\t7\n",
      "  Malignant |\t2\t112\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "TN,FN,TP,FP = confusion_matrix(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Performance Metrics ======\n",
      "\tAcc.\t: 0.9736\n",
      "\tTPR\t: 0.9825\n",
      "\tPPV\t: 0.9412\n",
      "\tTNR\t: 0.9692\n",
      "\tF1\t: 0.9614\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "metrics= getMetrics(TN,FN,TP,FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Scikit-Learns KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[218   9]\n",
      " [  2 112]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          2       0.99      0.96      0.98       227\n",
      "          4       0.93      0.98      0.95       114\n",
      "\n",
      "avg / total       0.97      0.97      0.97       341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(x_train,y_train)\n",
    "pred = knn.predict(x_test)\n",
    "print confusion_matrix(y_test,pred)\n",
    "print '\\n'\n",
    "print classification_report(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,u'k (No. of Neighbors)')"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAAElCAYAAABwGzxqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl4VOXZx/HvHQJhSRQQXCAElLBIFNES3JBFUWrdCSlq4QW1CtUqb7GtrFpZBERp3atVitZakEXcUKtSVJAXY2ULKCRgDBBUUGQnJOR+/zgnMAxZZpKZOTPJ/bmuucicec4zv5nM5OZszyOqijHGGFMbxHkdwBhjjIkUK3rGGGNqDSt6xhhjag0resYYY2oNK3rGGGNqDSt6xhhjag0resYYY2oNK3rGGGNqDSt6xhhjag0resYYY2qNeK8DeCUhIUGbN29erT4OHz5MnTp1QpQoMixzZFjmyLDMkRPNubdu3XpIVRMCaVtri17z5s3ZsmVLtfrIzc0lNTU1RIkiwzJHhmWODMscOdGcW0S2B9rWdm8aY4ypNazoGWOMqTWs6BljjKk1au0xvapShawsmD8fvtnYhNZtoV8/6NbN62TGmKo6fPhwxJ5LVSP6fKHide5QnURjRS8I2dlwy437Wb9B6K9zaFucT0F8Cn2mZ9KhvTJzdkPS0rxOaYwJ1MGDB8nJyeHQoUMRfd6VK1dG9PlCxcvc9erVo127dtSvX79a/VjRC1B2NlxywSHuPPA4i0omkcRe54FieIy7mPLlGLqfP4Ily+tZ4TMmRuTk5NCkSRNOPfVURMTrOKYcqsq2bdtYt24dSUlJpKamVvn3ZUUvAKrOFt6dBx5nUsmo4x5PYq+z/AAMGXAPWdkNPUhpjAnG4cOHOXToEKeeeirx8YH/KfQ9xLFzexFNmte1QxwRcNppp/H999/z5ptvctFFF3H++edXqfDZiSwByMqC9RuEUSUTK2w3smQSX22IIysrQsGMMdUWzB/O7GzodvZ++nQ/wPePvkTzGVP5/tGX6NP9AOln7Wft2jAGreVKf0/NmjVj2bJlHDhwoEr9WNELwPz50F/nkMi+CtslsZf+Ood58yIUzBgTMaWHOK748nG2Fp3MjOLBTGQcM4oHs7XoZK748nG6n3/ICl+Y1atXD1Xl4MGDVVrfil4Adm4vokVxfkBtWxTn89OO4jAnMsZE0tFDHNOZVDLq6DF9V+khjjsPTGfIgP0hf/7FixfTtWvXMh/r1asXb731VsifM1BDhgzhySefPHL/oYce4uyzz6agoICZM2ciIrz88stHHn/rrbfo1avXkfsiQp8+fY7ps1mzZuTl5YUlrxW9ADRpXpeC+JSA2hbEp9C4mR0qNaYmqU2HOIqLq/afdlXl3nvv5Y033uCjjz6iRYsWALRp04Zx48ZRWFhY7robN27kvffeq9LzBsuKXgD69YO5ksleGlXYbg+JzJVMMjIiFMwYE3KFhbB799HbgQPOIY6MIA9x7N17bD+B1JIDBw4wYMAAOnXqxDnnnMMVV1xxXJtdu3Zx+eWXM2HChOMe27NnD7fffjvdunWjc+fODBs2jKKiIgCmT59Oeno65557Lt26dWP58uVH1hMRHn30UXr16sWoUaOYOXMmffv25aabbuLss8+ma9eubNq0qdzchw8f5rbbbmP16tV88MEHNG3a9MhjP/vZzzjnnHN4+umny11/woQJjBw5ElWt/E2qJit6AUhPhw7tlclxYytsNyVuDB3bl5CeHqFgxpiQmzwZTjzx6O3uu51DHC2DPMRx/vnH9vPhh5Wv++6777Jz507WrVvHqlWrmDVr1jGP5+fnc+mllzJ48GDGjRt33Pr33nsvPXr04LPPPmPVqlUUFxcf2fU4aNAgsrKyWLFiBY8//ji33XbbMesWFhayePFipk2bBsDy5cuZMmUKa9asoU+fPkydOrXc3BMmTGDTpk289dZbJCYmHvf45MmTmTp1Krt37y5z/euvv56GDRvyyiuvVPwGhYAVvQCIwMzZDXm6wQjGxE1mD8f+UveQyJi4yTzT4HfMnG2XKxgTy0aNgl27jt6eeMI5xLE1yEMcy5cf289ll1W+7jnnnMNXX33FnXfeyezZs6lbt+6Rx7Zt20bPnj159NFHGThwYJnrL1iwgGnTptGlSxfOPfdcPvnkE3JycgBYsWIFPXv25KyzzmLYsGGsW7fumIvyb7311mP66t69O61btwbgwgsvZOPGjeXm7t27N2vXrmXJkiVlPn7mmWdy9dVXV1g4p06dyrhx48I+UIAdfApQWhosWV6PIQPu4YkNw8nQubRwR2R5tSST1iklfPJWgl2YbkyMS0hwbr769YM+0zN5gjsr3MVZeohjUQaUscFTqTPOOIN169axaNEiPvjgA/74xz8eGQWlSZMmtG7d+rgTQXypKgsWLOCMM844ZvmhQ4fIyMhg8eLF/OxnP2P37t2ceOKJHDp0iHr16gEct4XmO/JJnTp1KjzW17NnT+666y4yMzN55ZVXuPzyy49r8+CDD3LOOeccKaT+unfvzllnncUzzzxT7vOEgm3pBSEtDbKyG/Lh0gaccu8gvs78DafcO4iBv67PSckN6dTJ64TGmHCI1CGOLVu2ICJce+21PPLII6gqmzdvBpwitGDBAr755huGDRtGSUnJcetfe+21TJky5UiB2rlzJ7m5uRw8eJCioiJatWoFwBNPPFG1gBXo1asXc+fO5aabbirzpJSWLVvy61//msmTJ5fbx5QpU5g8eXKFJ71UlxW9KkhPhylTYPxDPzJlCkybBuvWwfvve53MGBMOkTrEsWbNGi666CI6d+7Meeedx6BBg+jcufORx+vWrcusWbMoLCzkf/7nf47b+vrLX/5CfHw8Xbp0oXPnzvTp04e8vDxOOOEExo8fT7du3ejRowcJ/puyIdKzZ09ee+01Bg4cyDvvvHPc4yNHjiz3uB5Ap06duOqqq9i7d2+5bapLInG2TDRKTk7WUM6cPnUq/PvfgR2s9lI0z35cHsscGbUt8+HDh1m5ciVdunQJeAT/tWthyABn0HnfQxxzJZOO7Uts0PkwKv195eTkUFBQwJAhQ46cJSoiW1U1OZB+7JheiNx9N/idDGWMqWFKD3FkZcG8eYP4YUcxpzSLZ1EGdtZ2jLCiFyIN3T0aTz8Nw4ZBnO04NqbGSk8vLXL2JzTW2J/mEIqLg0mT4LXXvE5ijAlUbT3EE2tKf0/V/X1Z0Quh+vVhzBi4/36IwYmRjalV4uLiEJGITyBrqubQoUOoarWLnm2bh9httzkntcyeDTff7HUaY0x5RIRmzZqxefNmzjjjDOLsmETUKikpIS8v75gzP6N2ElkRaQe8CDQDfgKGqOq6MtqNBW5x776iquPc5TcADwIlQF1gATBWfcq9iDQHsoFPVLV/GF9OpRIS4KWXICWwwRuMMR5q2bIl69evZ/Xq1V5HMZUoKiriu+++Y9++fdStW5eGDat2aUgktvSeBZ5T1Zki0h94AbjQt4GI9ABuAjoDxcBSEVmiqu8BHwCvq2qJiNQDlgDLgTd8ungaWAgkhf3VBKBnTzh0CNavhw4dvE5jjClPnTp16NSpE5s2beKdd97hcASOS+zdu7fM8SmjnZe5VfXIxfhxcXFcddVVVb7WMKxFT0ROBs4DSocKnwc8KSJtVDXPp+kAYKaq7nPXm4FTBN9T1T0+7eoDCThbfaXP8SvgO+Bz4OowvZSgvfYajBzpFD53lB9jTJQ644wzuPHGG/npp5/CfmLL5s2bj4yMEkuiIbeI0LhxY0466aQq9xHuLb1WQIGqFgOoqopIPpAC5Pm0SwE+8rmfBxzZTSkiFwF/BdrjbNW97S5vAYwAevq2jwb9+8ODD8Lf/w5Dh3qdxhhTmZNOOqlaf0yDEWuDAJSK1dy+IrF70/+/TeUdfdTy2qjqp0Bn99jdfOAS4GPgb8AfVXVvZQc1RWQEToEEICkpidzc3IBeQHl27NhR4eO/+U0jHnigOd27f0NCQnScFl1Z5mhkmSPDMkdGLGaG2M3tL9xFbzOQLCLxqlosTmVqBfhPTJUPtPG537qMNqjqdhF5G8jEKXoXAi+4BS8RaCAi76lq3zLWnQ5ML72fnJysofhfS0V93HUX5ORA06ZtOe20aj9VyMTi/9Ysc2RY5siIxcwQu7l9hfUcXVX9HlgBlE7+lAHk+R3PA5gDDBaRRiKSANwKzAIQkQ4iEuf+nIRz3G61239TVW2jqm2A3wPvlFXwvBIXB48/DqecAu7kxcYYYzwUiQtThgJDRWQDMBK4DUBEFopIVwBVXQy8CqwBvgT+rarvuutnAtkisgpYhnM25/MRyB0yt94Kf/mL1ymMMcaE/Zieqq7H7xIFd/kv/O6PB8aX0W4iMDGA55kJzKxqznC68UYYONAZkzMpKi6qMMaY2smGIIiAvn2hY0d47DGvkxhjTO1mRS8CRGDCBFi6FGxsW2OM8Y6NvRkhvXtDr15OATTGGOMN29KLoIMH4dproYZc7mKMMTHHil4ENWjgXLrw8MNeJzHGmNrJil6ETZgATz0F337rdRJjjKl9rOhFWNeucMUV8OyzXicxxpjax05k8cDzz8OJJ3qdwhhjah/b0vPASSfB5s0wY4bXSYwxpnaxoueRgwedAam//trrJMYYU3tY0fPImWdCZqZzYosxxpjIsKLnofvvh1degQ0bvE5ijDG1gxU9D6WmwuuvQ3Ky10mMMaZ2sKLnsb594aef4JtvvE5ijDE1n12yEAWmTIGCApg71+skxhhTs1nRiwIjR0LbtvDyy5CdDTu3F9GkeV369YNu3bxOZ4wxNYcVvSjw44/QrOF+hv6PMKDOHFoU51MQn0Kf6Zl0aK/MnN2QtDSvUxpjTOyzY3oey86GSy44xKCfHudbPZkZxYOZyDhmFA9ma9HJXPHl43Q//xBr13qd1BhjYp9t6XlIFW65cT93HnicSSWjjns8ib3O8gMwZMA9ZGU39CClMcbUHLal56GsLFi/QRhVMrHCdiNLJvHVhjiysiIUzBhjaigreh6aPx/66xwS2VdhuyT20l/nMG9ehIIZY0wNFfaiJyLtRORTEdkgIp+JSKdy2o0VkY3ubYLP8htEZLWIrBSRtSIySUTEfWyAiKwQkWwRWSMid4f79YTSzu1FtCjOD6hti+J8ftpRHOZExhhTs0ViS+9Z4DlVbQ88DLzg30BEegA3AZ2BTsCVItLXffgDoIuqdgHOBS4HrnEf2wJcqapnAd2B4SJycThfTCg1aV6XgviUgNoWxKfQuJkdgjXGmOoIa9ETkZOB84CX3UXzgNNFpI1f0wHATFXdp6qFwAycIoiq7lHVErddfSABKHEfW6qq37o/7wK+Ak4P2wsKsX79YK5kspdGFbbbQyJzJZOMjAgFM8aYGircW3qtgAJVLQZQVQXyAf/NmxTAdyCuPN82InKRiKwGvgc+BN72fyJ3t+mFwKIQ5g+r9HTo0F6ZHDe2wnZT4sbQsX0J6ekRCmaMMTVUJPaXqd99CaDdMW1U9VOgs4g0B+YDlwAfH2kskgy8DgxT1YKyOheREcCI0vtJSUnk5uYG+hrKtGPHjmqtDzB+Wj1uyvhftBBGlUwiib1HHttDIpPjxvBM/f/llWnfk5t7qNrPF4rMkWaZI8MyR0YsZobYze0v3EVvM5AsIvGqWuyegNIKZ2vPVz7Qxud+6zLaoKrbReRtIBO36IlIC5zjfhNVdU55QVR1OjC99H5ycrKmpqZW6UX5qm4fqamwNMu5Du/JDcPJ0Lm0KM4nnxTm18mkU8cSlsyuT1paYMf+AnvO6r/uSLPMkWGZIyMWM0Ps5vYV1qKnqt+LyApgIDATyADyVDXPr+kc4EkReRooBm4FxgKISAcgR1VLRCQJuBp40X3sNJzdnVNV9cVwvpZwSkuDrOyGZGXBvHmD+GFHMZu+jOeSJHj3Xa/TGWNMzRGJ3ZtDgZkiMhrYDQwGEJGFwP2q+rmqLhaRV4E17jqzVLX0z30mcLOIFAF1gLnA8+5j43GO/Q0XkeHussdU9e9hf1VhkJ6Oe9wunv/+F95/3+tExhhTs4S96KnqepwTTPyX/8Lv/nicIubfbiJQ5pAlqno7cHtokkaXn/3MuRljjAkdG5Elij3yCLzyitcpjDGm5rCiF8UOHXKGKjPGGBMaVvSiWO/esHgxlJRU2tQYY0wArOhFsa5dobAQ1qypvK0xxpjKWdGLYnXrwoIFkBK6S/SMMaZWs6IX5S67DBISvE5hjDE1gxW9KPfll9CyJRTbrELGGFNtVvSiXIcOIAJffOF1EmOMiX1W9KJcXBz06gWLYmbuCGOMiV5W9GJA796wfLnXKYwxJvZZ0YsBd9wB8+Z5ncIYY2KfFb0YkJAAn38OX3/tdRJjjIltVvRixPTp8NJLXqcwxpjYZkUvRlx6KfznP16nMMaY2GZFL0ZceiksWwYHDnidxBhjYpcVvRjRti1ccw18953XSYwxJnZFYuZ0EwIiMHeu1ymMMSa22ZZeDFm/HkaN8jqFMcbELit6MaRBA5g2Dfbs8TqJMcbEJit6MSQlBU4/HT75xOskxhgTm6zoxZjevW0cTmOMqaqwFz0RaScin4rIBhH5TEQ6ldNurIhsdG8TfJbfICKrRWSliKwVkUkiIpWtV1PdcQdcdZXXKYwxJjZF4uzNZ4HnVHWmiPQHXgAu9G0gIj2Am4DOQDGwVESWqOp7wAfA66paIiL1gCXAcuCNStarkbp2df5Vdc7oNMYYE7iwbumJyMnAecDL7qJ5wOki0sav6QBgpqruU9VCYAZOMUNV96hqiduuPpAAlFS2Xk12zTWwYIHXKYwxJvaEe/dmK6BAVYsBVFWBfCDFr10K8I3P/TzfNiJykYisBr4HPgTeDmS9mqpNGzuuZ4wxVRGJ3Zvqd7+8nXJaXhtV/RToLCLNgfnAJcDHla13zJOKjABGlN5PSkoiNze34uSV2LFjR7XWr6qOHRvx2GNNyc3dHPS6XmWuDsscGZY5MmIxM8Rubn/hLnqbgWQRiVfVYvcElFY4W3u+8oE2Pvdbl9EGVd0uIm8DmThFL6D13HWnA9NL7ycnJ2tqamqwr+c4oegjWE2awD33QFJSKqecEvz6XmSuLsscGZY5MmIxM8Rubl9h3b2pqt8DK4CB7qIMIE9V8/yazgEGi0gjEUkAbgVmAYhIBxGJc39OAq4GVle2Xk120knO3Honn+x1EmOMiS2RuE5vKDBURDYAI4HbAERkoYh0BVDVxcCrwBrgS+Dfqvquu34mkC0iq4BlOGdzPh/AejXaSSfBunVepzDGmNgS9mN6qroev0sU3OW/8Ls/HhhfRruJwMQK+i9zvZruo49g+HDIyfE6iTHGxI6At/RE5GQRucT9Od69Zs545JJLnF2c+WUewTTGGFOWgIqeiPQDPgP+4S5KA+xKMQ8lJUF6us2mbowxwQh0S2808DNgJ4CqrsI5U9J46JproIacRWyMMRER6DG9ElX9QY4d9+pQGPKYIIwe7XUCY4yJLYFu6e0RkVNwLwQXkd64W33GW489Zsf1jDEmUIFu6Y0EFuKMm7kYaAdcE65QJnDz5zuTy95xh9dJjDEm+gW0paeqWcClwM3Aw0Caqn4RzmAmMJdeaiezGGNMoAI9e/NpVd2lqu+o6kJV/UlEng53OFO50qKn/iOcGmOMOU6gx/QuKGPZcRecm8g7/3y45RY4eNDrJMYYE/0qPKYnIpnAL4E2IvKqz0MnAvvCGcwEpl49mDzZ6xTGGBMbKjuRZQPO3HXdODqHHcBunHntTBR4801YuBCeecbrJMYYE90qLHruReirRORtVd0eoUwmSKecArNnw1NPQVwkhhA3xpgYFeglC3vcSVi7APVLF6rqL8OSygTlvPPg8GFYtQrOPdfrNMYYE70C3S74G5AK9AA+AdoCW8MVygQnPh569IBFi7xOYowx0S3QLb0uqnq2iKxW1SdEZCYwN4y5TJCmTXNmVDfGGFO+QLf0Drj/FotIQ1XdA7QMUyZTBR07Olt8xcVeJzHGmOgVaNH7UUSa4AxF9o6IzAe2hS+WCZYqnHkmfP6510mMMSZ6BVr0rlLVncA44DlgEZARtlQmaCJ2XM8YYyoT6Nibh91/VVX/qapPApeFNZkJWu/eVvSMMaYilRY9EekvIveKSAf3fl8R+QKwcUCizKWXwoYNzuULxhhjjldh0ROR6TjFLR14TUQeBWYDfwfOCn88E4yOHSEvD+rU8TqJMcZEp8q29K4EzlXVG3F2Z/4WuERVn1DVgM4TFJF2IvKpiGwQkc9EpFM57caKyEb3NsFn+QARWSEi2SKyRkTu9nlMRGSaiKwVkdUi8h8RSQ0kV00kAl9+aVMNGWNMeSoregdUdS+Aqm4DNqjqmiCf41ngOVVtjzMX3wv+DUSkB3AT0BnoBFwpIn3dh7cAV6rqWUB3YLiIXOw+di3OBfNdVLUzznigDwWZr0ZZtgweeMDrFMYYE50qK3onisgvSm9AA7/7FRKRk4HzgJfdRfNwZl9v49d0ADBTVfepaiEwA6cIoqpLVfVb9+ddwFfA6T7rJgD1RUSAE3CKZK116aXwf/8H+2wODGOMOU5lI7LkA3/wub/Z577iXLdXkVZAQemuUFVVEckHUoA8n3YpwEc+9/OA/v6dubtGLwTucBe9CfQCvgX24AyN1rOSTDXa6adDixawdClccYXXaYwxJrpUNstC7xA8h/+c3hJAu+PaiEgy8DowTFUL3MXnAR1xRofZDUwBngSGlLH+CGBE6f2kpCRyc3MDewXl2LFjR7XWD5cbb2zMt98Wkpt74LjHojVzRSxzZFjmyIjFzBC7uf0FOvZmVW0GkkUkXlWL3V2QrXC2IH3lA2187rf2bSMiLYAPgImqOsen3RDgP6r6k9vuRcrZ+lTV6cD00vvJycmamlr9c15C0UeoTZlS8ePRmLkyljkyLHNkxGJmiN3cvsI6+5qqfg+sAAa6izKAPFXN82s6BxgsIo1EJAG4FZgFICKn4ZygMlVVX/RbbxNwmYjUde9fA2SH/IXEmMJCyMiAXbu8TmKMMdElElOODgWGisgGYCRwG4CILBSRrgCquhh4FVgDfAn8W1Xfddcfj3PMb7iIrHRvt7iPPYWzRbhGRFYDvYG7IvCaolpCAmRnw8cfe53EGGOiS6W7N0WkDvCQqt5XlSdQ1fU4J5/4L/+F3/3xOAXOv93twO3l9F1Y3mO1Xe/ezvV611zjdRJjjIkelW7pueNudotAFhNCl15q43AaY4y/QE9keVNE7sO5fu7IFWCquj8sqUy19ekD9et7ncIYY6JLoEXvEfdf30GmFbBRHqNU06Zw7bVQVAR161be3hhjaoNApxaKK+NmBS/KPfgg/O53XqcwxpjoEfDZmyLS0h38+ZfudXMmynXpYsf1jDHGV0BFT0SuA1bhjId5M7BSROy8wCjXsyesXw/btnmdxBhjokOgW3oPABeo6vWqej3OJQgPhi+WCYXGjeHcc51xOI0xxgR+IksdVT0yUKWqbhSRSFzYbqrpww/hhBO8TmGMMdEh0ML1vYjc5o6diYgMBmrG6KM1XIMGTuEzxhgTeNEbhjPyyX4ROeDev6PiVUw0OHQIrrwS8vK8TmKMMd6rtOi5uzGbqeoFQHPgZFW9UFU3hT2dqbbEROjWzRmSzBhjartAhiErAZ5wf96rqnvCnsqEVO/edumCMcZA4Ls3vxSRM8KaxIRN377OzAvGGFPbBXr25sk41+YtAfaWLlTVX4YllQmp7t2dojdyJHyzsQmt20K/fs5uz+pShawsmD8fdm4voknzuiHr2xhTuVj8DnqZOdCiN8u9mRiTnQ233Lifr74SMphD28P5FMSn0Gd6Jh3aKzNnNyQtrXp9r98g9Nc5tCgOXd/GmMrF4nfQ88yqWuENZ1DpqZW1i7Vby5YttbpycnKq3Uc4rVmj2rhRoY6Om6y7SVR1/oOlCrqbRB0dN1kbNyrU7Ozo6ttftL/PZbHMkVGbM0fyO6gamtzhygxs0QD/9gfWCP4TaIexcqvpRa+kRLVr2j4dHTf5mA+W/2103GTtmrYvavouSzS/z+WxzJFRWzNH+juoWv3c4cwcTNEL9ESWN0XkPhE5WUQalt7Cs+1pQiErC9ZvEEaVTKyw3ciSSXy1IY6srOjo2xhTuVj8DkZL5qrMp6eAYPPpRbX586G/ziHx6Jy/ZUpiLxklc5g3bxCvvgo//nj0sZEjoV07+PWvnf+ClUpMhIwA++6vTt/p6dV5NcYYX8F8v6PlOxgtmQMqeqpq42zGmJ3bi2hRnB9Q25aH8/lhRzEd0uJJTDy6vPQyh1atjm2fl1tEywD7blHs9B34/6+MMZUJ5vsdLd/BaMlcYY8i0lFVv3J/jlfVYp/HLlZVG78/SjVpXpeC+BQorrxtQXwKpzSLL3fC2QceOPb+yJHB922MCZ2qfL+9Fi2ZK9uCe8Xn58/8HnsikCcQkXYi8qmIbBCRz0SkUzntxorIRvc2wWf5ABFZISLZIrJGRO72W+9sEVksIl+KyHoR6RdIrpquXz+YK5nspVGF7faQyFzJJCMjOvo2xlQuFr+D0ZK5sqIn5fxc1v3yPAs8p6rtgYeBF457EpEeOBPUdgY6AVeKSF/34S3Alap6FtAdGC4iF7vrNQQWAGNV9UwgDfgkwFw1Wno6dGivTI4bW2G7KXFj6Ni+JKh95+Hs2xhTuVj8DkZN5opO7QS+KOvnsu6Xs/7JwE9AvHtfgG+BNn7tngL+4HP/TmBmOX2+BQx0f/418HKgp6r63mr6JQuqqtnZlV8T06TRwSpdxxPOvv1F+/tcFsscGbU5c3a2auOGhXofZX8HR4XwO6gamtylfzdGSmj/bhDEJQuV7TStLyJnusXK92eA+gHU1FZAgbrHAlVVRSQfSAHyfNqlAB/53M8D+vt35u4avZCj0xp1Ag6KyFtAMrAauFdVtweQrcZLS4Mly+sxZMA9PLFhOBk698joB3Mlk47tS/hkdkKVRj8or++tdVKYo5l0OrPqfRtjKpeWBhOm1mP8yHt4+tCx3+9ZhzM5rXkJn3wYXd/BtDT45P8zWJgyAAAfw0lEQVTqccuN9/BUiP8mBaqyotcQWOhz3/dnJTD+7crbLaoVtRGRZOB1YJiqFriL6wJ9gQuAAmAizlbjcWOCisgIYETp/aSkJHJzc/2bBWXHjuifRzchAf61AFavTuC9967my20HaH5aA17su53OnQsBqOrb4N/31zuVpCbCP/pu5+yzCxGpet++YuF99meZI6O2Z/75z+Hyy2Ht2mO/gyOa7eGZZ5pSXLyR3NxA/1RXLBS5Dx4UMjKSeeqp7ezeHXdM5lD8TQpIoJuEVbnh7N7cRTV3bwItgK+AwX7r/R54yed+JyAvkGy1YfdmWSKR+fvvVdu3V92xIzT92fscGZY5MkKVedo01bffLvuxkhLVCy5QfeihkDyVqoYm96OPqp57rpMvlAjDiCxVLajfAyuAge6iDLco5fk1nQMMFpFGIpIA3Io7wLWInAZ8iDP+54t+670KpIvICe79nwOrQv5CTFCaN4fTT4dp07xOYkzN9O23zqVEzZuX/bgIzJgBt90W2VwV2bsXpkyBCROcfF6JxEXnQ4GhIrIBGAncBiAiC0WkK4CqLsYpYGuAL4F/q+q77vrjcY75DReRle7tFne9fJxRYpaJyCqgD3BXBF6TqcSECfDEE/Ddd14nMabmmTIF+vShwjMczzwTGjSAjz+OXK6KfPQRdOgAv/iFtznCfsWiqq7HOfnEf/kv/O6Pxylw/u1uB26voP+XgJeqn9SEUno6XHEFvPsuDB7sdRpjao4ff4TnnoNlyypvu2oVXH01fP01nHRS+LNV5KqrnAmtvdzKg8hs6Zlaas4cK3jGhFrTprB2LZxzTuVtu3eHCy+ERx6pvG04PfUUvP02xHs/MIwVPRM+8fGwZAlMnux1EmNqhm++gXnznGPmgfL6UMOPP8Lo0ZCU5M3z+7OiZ8KqaVN48EHIy/M6iTGxb/x4WLAguHW6dYOJE+Hw4fBkqswjjzgZevTw5vn9RcHGpqnJOnWCzEznf5svHDcAnTEmUDk58M9/QnZ28Ov+7/9CURHs3g0nnFB5+1DZtQsefxw++CByz1kZ29IzYffAA86XdfNmr5MYE7sefBAGDoTU1KqtP3y4s5sxkk48ET7/HC64ILLPWxHb0jNhl5rqnEXmPy+fMSZwgwc7p/xX1V13Qdeu8Ic/QOvWoctVnm3b4LPP4Lrrwv9cwbAtPRMRHTrAhx/Chg1eJzEm9qxb5ww3lpJS9T7S0pzpfSZODF2uijz0ELwUhReTWdEzETNvHowZ43UKY2LLypXOFtr2EAyj/6c/wY4dUFJS/b4qkp8Pzz/v7JKNNlb0TMSMGeNcq7NypddJjIkdDzwAQ4eWP+RYMNq1g9deC/8F4hMnwg03wFlnhfd5qsKKnomYli2dL+/993udxJjY8NlnzpmPI0eGrs/Dh+GSS+DLL0PXp79+/ZzLK6KRFT0TUSNHwqBBXqcwJjbs2+ccGzvllND1WacOnH22s6szHHJznSmPqnqWabhZ0TMRdcopznV7OTleJzEmuhUVQe/ezqUGoTZmDLzxhnNWdSh99ZWzS3PbttD2G0pW9EzE7d3rHJhfssTrJMZEr5//HF59NTx9JyfDHXc418+G0p/+5Fxacdppoe03lOw6PRNxiYnOCBHjxsF//uN1GmOiz6JF8MUXzkwl4TJ1KiQkhK6/NWvg9dej/7Ik29Iznvjd75yzOBct8jqJMdFFFcaOdS4ib9w4fM9Tv74z5VCoTiz74QfnTNNoH4TCip7xROPGzuwLe/Z4ncSY6LJli3MI4J57wv9cJ5wAf/4zLF1avX4OH4ZevUJ7lmm4WNEznhk2zBmiqLjY6yTGRI9WrZwTTBITw/9czZo5e13GjateP9dfD6+8EppM4WZFz3jq/feda4ZUvU5ijPfeessZxSSSs4uPGAErVsDHH1dt/WXLYPFiZ5i0WGBFz3jq4oudufZef93rJMZ4q6TEmQWhadPIPm/jxk7Ruuiiqq0/bpxzWUUoRoyJBCt6xlMNGzpf9PvvD/94gMZEszlzYOdOuP32yD/3OefApk3OGaPB2LbNGWfz3nvDkyscrOgZz91+u7N7c/16r5MY451HH3W2murX9+b5FyxwhgkM5lDDaac5F6Q3aRK+XKEW9qInIu1E5FMR2SAin4lIp3LajRWRje5tgs/yASKyQkSyRWSNiNxdxrr1RWSdiHweztdiwqN+fefA/Zlnep3EGO8sXAi33OLd8991lzPR8xtvBNb+ww+d449xMbbpFIm4zwLPqWp74GHgBf8GItIDuAnoDHQCrhSRvu7DW4ArVfUsoDswXEQu9utiErAsTPlNBMTFwZNPwuzZXicxJrKKipytvMREqFvXuxyNGsGoUYEdalB1Dkt4tVVaHWEteiJyMnAe8LK7aB5wuoi08Ws6AJipqvtUtRCYgVMEUdWlqvqt+/Mu4CvgdJ/nuARoB/wjfK/EREJiovNFKiryOokxkTNzJjz3HMRHwfhYQ4c6W5uVXUb01lvOCWi//W1EYoVUuLf0WgEFqloMoKoK5AP+8/+mAN/43M8row3urtELgUXu/UbAX4DfhDq4ibyBA50v/osvep3EmMgoLIQJE5zdhNFQ9OrXd4YI/PFH54Lz8jz8sLNV2KhR5LKFSiTeZv/DouVdgaIVtRGRZOB1YJiqFriLpwFPqepWEWlXUQgRGQGMKL2flJREbm5uZdkrtGPHjmqt74VozzxsWCKTJjWlR4/8I8cKoj1zWSxzZMR65pdfPpEGDU7gvPM2U80/RyGjCldd1YqhQ3dy3XV7jyz3zf3II3VITCwhNzcGL7BV1bDdgJOBXUC8e1+Ab4E2fu2eAv7gc/9OnN2dpfdb4OzWHOy33mqcrcI8t99CYG0g2Vq2bKnVlZOTU+0+Ii3aMx8+rLp587HLoj1zWSxzZMR65q+/Vs3K8i5LeWbMUE1NVT106OiynJwcLS5WfeIJ1f37vctWFmCLBliXwrqlp6rfi8gKYCAwE8gA8lQ1z6/pHOBJEXkaKAZuBcYCiMhpwIfAVFU9ZseXqnYu/VlEegGPqGrXsLwYExFxcXDqqfDUU85ElwsXwjcbm9C6rTMbc7du1X8OVcjKgvnzYef2Ipo0rxuyvs1R4XqfffuNlc9GWZnPOsuZW7JNm+rnDrVBg5yxcV98ETp3Ppp770H4/HNnWqJYFYndm0OBmSIyGtgNDAYQkYXA/ar6uaouFpFXgTXuOrNU9V335/E4x/eGi0jpdIqPqerfI5DdeODLL2Hc7/dz6JDwy7g5tC3OpyA+hT7TM+nQXpk5uyFpaVXrOzsbbrlxP+s3CP11Di1C2Lc5Klzvs3+/sfDZKCvz1vgUHivOZNIYZe7C6PvMxcc7J7VMGrufH348mjufFPbUyeTi82L4uxLoJmFNu9nuzei0Zo1q40aFOkom624SVZ3/JKuC7iZRR8dN1saNCjU7u+p9j44Lfd/+ov19LkuoMofrfQ7n78+rzKNC+JkLpUh+V0KBIHZvel58vLpZ0Ys+JSWqXdP26ei4ycd8yfxvo+Mma9e0fVHTd1mi+X0uTygyh+t9jsXPRqQ/c6ESi7mt6FnRK1c0Z16+XDWp7n7dQ6MKv2y7SdTEugf0s8+io++yRPP7XJ5QZA7X+xyLn41If+ZCJRZzB1P0ouDKEGMc8+dDf51DIvsqbJfEXvrrHG6+edAxxxRefhl++unYC2br14dZs+Cvf4XriwPve968QaSnV+fV1E7B/A6vLz76OxwzBtLTnRMofCcW/vOfoUUL+NWvAv/9ZZQc+9lo0QKefhoWLYLHHz/atnNnGD8eHnoouM/GvfcOOmYmhGHD4Oc/d65vy8s7uvzEE4P7PEfLZy7Y72G05A6UFT0TNXZuL6JFcX5AbVsU53Nqs2Iuu+zoRzg+3pm14bLLjrYrHdbp0P4i2mjgff+woxj7egQvmN9hiuaT5/4OmzVzlvXoAQcPHm2TmOie0dusiJTcwPptefjYz0bjxs7y00479rORnOz8G1dSREoQn41v6x/7uWvZ0vn3/POhbdujbZd9UkSrID7P0fKZC/Z7GC25AxU7SU2N16R5XQriU5yLVipREJ/CxT3judtv+PH69TluGUBym+D6PqWZfTWqorq/w/Km1bm4Z10KPq/eZ+PMM8se1Lx9p7oUvBN43+ecd3zfADfddOz9rVtj8zMX7O8wWnIHLND9oDXtZsf0ok8sHrcpTzS/z+WxY3qxkzmcYjE3QRzTi7FJIUxNlp4OHdork+PGVthuStwYOrYvCeo4Qjj7NkeF632Oxc9GrH7mYjV3wAKtjjXtZlt60Sk7u/Lrg5o0Olil64PC2be/aH+fyxKqzNnZqifUL9T7CO37HIufjUh+5kIp1nITxJaeOO1rn+TkZN2yZUu1+sjNzSU1NTVEiSIjFjKvXQtDBjgjWGTo3CMjY8yVTDq2L6nWSBDl9k0m7VJL+Mfc0IwyEQvvs79QZr7oItiSs5+fdoX2d+jJZyOKM4dTLOUWka2qmhxQWyt6VVfb/7CFW1YWzJsH+Zt+JOWMpmRkELJdKaV9/7SjmMbN4tm2zZk48x8hmpUxlt7nUqHKXFLiTD1zxx2wceOx73OofoeR/GzEQuZwioXcVvQCYEUvdkQic16ec2bff/8LnTpVv7/a+j6rws6dHHMdWzjV1vfZC9GcO5iiZyeyGIMz0v2QIfCnP3kcJMZ9+CF06VL5zNvGeMWKnjGuMWNg3z44dMjrJLFJFcaOhTvvjI5ZwI0pi300jXElJ8Pbbzt/vE3wFi6ETZuOHQbOmGhjW3rG+FCFyy93Dt6b4GzcCA884AwdZky0si09Y3yIwHnnwf33wzvveJ0mttxzj9cJjKmcbekZ4+ePf4QlS2DpUq+TxIaSEmcg55UrvU5iTOWs6Bnjp1kzZ5qYUF2zV9O9+irk5JQ9mLMx0cZ2bxpThrFjj05LZMpXXOwcx7v/fkhI8DqNMZWzLT1jypCQAAUFMHKknc1ZkU8/dd6fwYO9TmJMYKzoGVOOE0+E55+H997zOkn06tEDVq2yrWITO8Je9ESknYh8KiIbROQzESlzkCcRGSsiG93bBJ/lA0RkhYhki8gaEbnb57FLRWS5iKxzH58kIhLu12Rqh6QkuO8+GDfOtvbKMmcOvPkmNGjgdRJjAheJLb1ngedUtT3wMPCCfwMR6QHcBHQGOgFXikhf9+EtwJWqehbQHRguIhe7j+0EblLVTkBXoKfbjzEhcdddsHmzc+G1OergQRgxAvbv9zqJMcEJa9ETkZOB84CX3UXzgNNFpI1f0wHATFXdp6qFwAzc4qWqS1X1W/fnXcBXwOnu/RWqusn9+SCwEjgjnK/J1C4NG8L77zsXrJuj/vY3aNIEMjO9TmJMcMK9pdcKKFDVYgB3sr98IMWvXQrwjc/9vDLa4O4avRBYVMZjpwL9Afs/uQmps8+GrVth+XKvk0SHwkJ46CEYPx7i7KwAE2MiccmC/9GQ8o65aUVtRCQZeB0YpqoFfo+dALwJPKyqX5TVuYiMAEaU3k9KSiI3N7fy9BXYsWNHtdb3gmWumn/96wRefLExb7+dT506lbePhszBCibzU08lkJZWSDW/QtVW09/naBKruf2Fu+htBpJFJF5Vi92TTFrhbO35ygfa+Nxv7dtGRFoAHwATVXWO74oikgS8C7yhqtPLC+I+duTx5ORkDcXcUNE6v1RFLHPw7rsPZsyArKxUBg4MbB2vM1dFZZn37nVGq7nhBmfItmhQE9/naBWruX2FdeeEqn4PrABK/0xkAHmqmufXdA4wWEQaiUgCcCswC0BETgM+BKaq6ou+K4lIIk7Be09VJ2BMmNSr51yE/ac/QVGR12m88/jjzm5NY2JVJHZvDgVmishoYDcwGEBEFgL3q+rnqrpYRF4F1rjrzFLVd92fx+Mc3xsuIsPdZY+p6t+B4UA3oJGI3OA+NkdVJ4X/ZZnaZuBA2LXLGYWkNl6X9tNPMG0azJsXPVt5xgQr7EVPVdfjnHziv/wXfvfH4xQ4/3a3A7eX0/ckwAqciYj4eBg+HLZvd07gqG3Dbv35z86s6Jde6nUSY6rOzr0yJkjXXgsvHHe1ac3XrZuzpWdMLLOiZ0yQfv97mDgRDhzwOknkbNsGV10FXbt6ncSY6rGiZ0yQbrgBTj0V/vpXr5NExnffQbt2zvRBxsQ6K3rGBCkuDiZNgt27vU4SGVOmOJPEtmvndRJjqs/m0zOmCq680rmp1uwzGbduhWefhWXLvE5iTGjYlp4xVbR1K6SlOZcx1FR5eXDHHXDOOV4nMSY0rOgZU0UtWkCzZvCXv3idJDxU4eKLa+7rM7WTFT1jqkjEOYtz+nT48Uev04TesGHOJLrG1CRW9Iyphh494IIL4N//9jpJaOXkwIsvQs+eXicxJrTsRBZjqumtt2resGQPPgi/+pWdsWlqHit6xlRT3brwn//AihXObOKxbtcu5/UsXep1EmNCz4qeMSFwwgkwZgx07AgffwzfbGxC67bQr58zfFd1qUJWFsyfDzu3F9Gked2Q9O3br2/mvLyat/VqDFjRMyYkEhLgxLr7ybxGGBA3h7bF+RTEp9BneiYd2iszZzckLa1qfWdnwy037mf9BqG/zqFFiPr277dtcT5b66Rw6bRMzjyzepmNiVqqWitvLVu21OrKycmpdh+RZplDb80a1caNCnWUTNbdJKo6G1CqoLtJ1NFxk7Vxo0LNzq5636PjQtt3uPqNtGj/bJQlFjOrRnduYIsG+LfftvSMqQZVZ2vpzgOPM0lHHfd4EnuZVDIKDsCQAfeQld2wan2XhK7vcPVrTCywSxaMqYasLFi/QRhVMrHCdiNLJvHVhjiysrzvO5yZjYl2VvSMqYb586G/ziGRfRW2S2Iv1xfNoV8/59q+6693ln/0kXO/9HbHHc7yuXMhIwOuLwqs737FR/vu0QP+9S/nsd/+9tj+P/jAyXxDcWD99tc5zJsX0FthTEyw3ZvGVMPO7UW0KM4PqG0K+XRMLeaW2+OpX99ZdsYZzsgnpZo2df49+2zo0LaIlC2B9Z2sR/uGo2NlXncdXHTR0XapqTDnX0W00sD6bVGczw87irE/FaamsE+yMdXQpHldCuJToLjytgXxKfzs/HhuvvnoslatOOZ+qQ4doOsFdSlYWvW+AS6/vPqZT2lmfyZMzWG7N42phn79YK5kspdGFbbbQyJzJZOMDO/7DmdmY6KdFT1jqiE9HTq0VybHja2w3ZS4MXRsX0J6uvd9hzOzMdEu7EVPRNqJyKciskFEPhORTuW0GysiG93bBJ/lA0RkhYhki8gaEbnbb73bRCTHXe85EbF9MSZiRGDm7IY83WAEY+Ims4fEYx7fQyJj4ibzTIPfMXN2cKf+h6vvcGY2JtpFokA8CzynqjNFpD/wAnChbwMR6QHcBHTGOdKwVESWqOp7wBbgSlX9VkROBP4rIl+o6lIROR2YAJwLfA+8DtzmPqcxEZGWBkuW12PIgHt4YsNwMnTukVFT5komHduX8MnshCqNbhKuvsOZ2ZhoFtaiJyInA+cBV7iL5gFPikgbVc3zaToAmKmq+9z1ZuAUwfdU9ciwt6q6S0S+Ak4HlgL9gddU9Tt3vb8Cf8SKnomwtDTIym5IVhbMmzeIrzf9SMoZTVmUQbV3D/r3/cOOYk5pFl/tvsOZ2ZhoFe4tvVZAgaoWA6iqikg+kALk+bRLAT7yuZ+HU9CO4e4avRC4w2e9b/zWSwlNdGOCl57u3HJzfyQ1tWlY+g711zacmY2JNpHYval+9yWAdse1EZFknN2Xw1S1IND1fNYfARyZ+CUpKYnc3Nzymgdkx44d1VrfC5Y5MixzZFjmyInV3P7CXfQ2A8kiEq+qxSIiOFt//lfG5gNtfO639m0jIi2AD4CJqjon0PV8qep0YHrp/eTkZE1NTQ329RwnFH1EmmWODMscGZY5cmI1t6+wnr2pqt8DK4CB7qIMIM/veB7AHGCwiDQSkQTgVmAWgIicBnwITFXVF/3WmwfcICKnuAV1WOl6xhhjjD9xZmUI4xOIdABmAicBu4HBqrpWRBYC96vq5267+4Eh7mqzVHW0u/xvwM1Ajk+3j6nq393Hbwfuwyngi4DfqGpRALkKge3VfHmJwN5q9hFpljkyLHNkWObIiebczVU1IZCGYS96NZmIbFHVZK9zBMMyR4ZljgzLHDmxmtufjchijDGm1rCiZ4wxptawolc90ytvEnUsc2RY5siwzJETq7mPYcf0jDHG1Bq2pWeMMabWsKJnjDGm1rCiFyQRqS8iC9ypklaKyLsi0sbrXIESkQdEREXkLK+zVEZEEkTkSXfqqLUi8rLXmSojIn1F5L8+02EN9jqTPxF5XETy/D8HgU4D5oWyMsfCd7G899rn8aj7Plbw+Yi572NZrOhVzXNAB1XtArzl3o96InIecAHlDNUWhaYAJUB7VU0D/uBxngq5owK9AtyiqucCVwPPikiSt8mOMxfozrGDtcPRacDaAw/jTAMWLcrLHO3fxfJyR/P3sbzMMfV9LI8VvSCp6kFVXahHzwD6P+AMLzMFwh3e7SngTo4fBDzqiEgj4BZgdOl7rarbvE0VsMbuvycAPwCFHmY5jqp+rKpbfJf5TANW+r/3ecDp0bLlVFbmWPgulpUbovv7WM7nI5a/j8ewold99wBveh0iAOOBl1X1a6+DBKgtTsEYKyKfi8gnInKZ16Eq4v4x+CUwX0S+AZbgDLt3yNtkATluGjCcLZBYmqorVr6LYN9Hz1jRqwYRGQ20A8Z4naUiInIhkA487XWWINTF+V/7OlXtCvwWmCUizb2NVT4RiQdGAdepamvgMuBFEYmVSeoCnQYs6sTKdxHs++g1K3pVJCK/B/oBV6rqfq/zVKIn0BH4WkTygGTgPRG50tNUFfsG5/jBPwFUdRXwNZDmZahKdAFaqOpSAFXNAgqAczxNFZgj04DBkeOTZU0DFnVi7LsI9n30lBW9KnAnpL0JuFxVf/I6T2VUdYqqtlDVNqraBtgC9FXVdzyOVi5V3YEzpVRfABFpDZwOrPcyVyVKC0cHABFJxdkttMHTVAEIYhqwqBJr30Ww76PXbESWILkzuG8GNgF73MWFqnq+d6mC4/7v8mpVzfY6S0VE5AxgBs60VIeBB1X1NW9TVUxEbgJG4/yvWICHVDWq5ngUkaeA64BTgR3AXlVNLW8aMM+C+igrM9CLKP8ulvde+7XJI4q+jxV8PmLu+1gWK3rGGGNqDdu9aYwxptawomeMMabWsKJnjDGm1rCiZ4wxptawomeMMabWsKJnaj13NPnEANvOd0fUQET+5K57ic/jvxWRmWGKioi0FZEv3FkcbvF7rI2b53mfZYkiEtAp2u5MBQ0CaJdX3qwAIrJYRK4O5PmqQkTuFpFR4erf1HxW9IwJkIh0Axqr6jKfxXnA1AjG6A8sU9VzVfXvZTy+F7i6KtMCqWoXVT1Q7YTVVDoqTDmeBW4XkRMilcfULFb0jHGJY6qIvC4iDctoMhR3GCYf84H6InJDOX3+0Z17bI2I/FNETgwgR6KIzBBnPr5sEXnAXf4/wO+ATHerrKzCVogzBczkcvpuJyJvi0iWiKwSkTt9HjuyxSsil7iZV4vIEyLyjd/WXYY4c+99LSJj/Z6mj7vFlyMi09whzRCRVBH5wO1zpYhc7/fc94rIYmCyiFwgzryEK9334DcA7uDd/wYGVPY+GlMWK3rGOOoDs4CGwA3ljOHYC/jUb5kCI4GHRKSO7wPuWIq3ABer6tnAPuChALKMA+oBnYHzgetFJFNVXwL+CrzkbpWtK2f9p4GzReRivzx1cOb7u1dV04ELgWHizOvm2y4B+Bdwp6p2BhZx/GwLjVX1IqAb8AcRaenzWCfgcpwxR3sDme7yfwKvun1mAi+ISCuf9RJUtZeq/gFn4O5H3dd5Fs7vptSnOIN5GxM0K3rGON4FVqrq3apaUk6bZOBb/4Wq+m9gK3Cr30N9gH/6jAn5jLusMn2Av6pqiaruA14KcL3SPIeA+3EmgvXVAWeA4FkishKneCThFCn/dgdU9RO3v9cA/3EtSwce3o4zDNjpPo+9qKpF7n8cXsbZ8kvCGZD7BXe9HJypl7r7rDfD5+f/4Exjc7+IdFfVnT6PfYvzuzAmaFb0jHF8CFwhFc9yvh8o70SP+4AHcLYUSwnHT9cTyEklVV3P1z/dLNf59bvD3XoqvZ2uqi/7rVvW8/s76PPzYaCi43DK0WmKKnpde48sVP0Lzszz23C2on2n4akPeH7s0cQmK3rGOCYAbwDvi0iTctqsxpkS5jiq+l+cLZff+Cx+H7jRp5DeAXwQQJb3cU7WEHFmrB4Y4Hq+eRRnF+FEn8Xrgf3usUHgyHE2//n+vgIale4eFZHrODobfCAGiUi8eybozcAHqrobWAkMdvtsC1wMLC2rAxHpoKqbVPVvOLuEL/B5+ExgVRB5jDnCip4xLlX9M87ut0UickoZTeYCFc15NgY4cmzLnSrmH8AyEVkDnOC2QUSu9b20wM8EnC2gNcBy4A1VnRvky0FV38XZ9Vh6vxi4BvilezLJWuB5/LZeVbUQp1j9VUQ+Ay4CvgN2BfjUX+AU6dXARzjvG8CvgIEisgqYB/xaVTeX08fd7glAK3AK970+j/3cXd+YoNksC8YEyN1iWwac7x5rq7FEJElV97g/9wZeBNpUcLwzUrk64Rzv7OFlDhO7KtoPb4zxoap7ROR/cU7aiIq5z8IoQ0R+h7M3qBC4yeuC52oFDPM6hIldtqVnjDGm1rBjesYYY2oNK3rGGGNqDSt6xhhjag0resYYY2oNK3rGGGNqDSt6xhhjag0resYYY2qN/wczulkyFTFT6QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a179e90d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_rate = []\n",
    "for i in range(2,18):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(x_train,y_train)\n",
    "    pred_i = knn.predict(x_test)\n",
    "    error_rate.append(np.mean(pred_i!=y_test))\n",
    "plt.figure(dpi=80)\n",
    "plt.plot(range(2,18),error_rate,'bo--',linewidth=1,markerfacecolor='red',markersize=10,label='sklearn KNN')\n",
    "plt.grid(alpha=0.5)\n",
    "plt.legend(loc='upper right',fancybox=True,shadow=True)\n",
    "plt.ylabel('Error Rate');plt.xlabel('k (No. of Neighbors)')\n",
    "#plt.savefig(savePath+'kNN_Elbow_ErrorRate.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(data_x,data_y,n):\n",
    "    data_x = np.asarray(data_x)\n",
    "    length_test = int(round(len(data_x)*(n/100.)))\n",
    "    # Create random integers between two numbers with no repeats\n",
    "    train_list = random.sample(range(0,len(data_x)), length_test)\n",
    "    train_list.sort()\n",
    "    test_list = np.arange(0,len(data_x))\n",
    "    test_list = np.delete(test_list,train_list)\n",
    "    data_y = np.array(data_y)\n",
    "    x_train,y_train = np.array(data_x[train_list]),np.array(data_y[train_list])\n",
    "    x_test,y_test   = np.array(data_x[test_list]),np.array(data_y[test_list])\n",
    "    \n",
    "    return (x_train,x_test,y_train,y_test,train_list,list(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test,train_list,test_list = test_split(data_x,data_y,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def getNeighbors(x_training,x_test,y_training,y_test,k=3):\n",
    "    y_prediction = {}; dist = []\n",
    "    counter = 0; y_pred = []\n",
    "    for i in x_test:\n",
    "        dist = []\n",
    "        for j in x_training:\n",
    "            dist.append(sum(np.absolute(i-j)))\n",
    "        dist_sorted = np.array(sorted(dist))\n",
    "\n",
    "        closest_indexes = []\n",
    "        for value in range(k):\n",
    "            index = np.where(dist==dist_sorted[value])[0][0]\n",
    "            closest_indexes.append(index)\n",
    "            \n",
    "        classes = np.array(y_training)[closest_indexes]\n",
    "        class_chosen = Counter(classes)\n",
    "        predicted_class = class_chosen.keys()[np.argmax(class_chosen.values())]\n",
    "        y_prediction[counter] = predicted_class\n",
    "        y_pred.append(predicted_class)\n",
    "        counter+=1\n",
    "        \n",
    "    return y_prediction,y_pred\n",
    "\n",
    "def confusion_matrix(y_predicted,y_true,prints=True):\n",
    "    TN=0;FN=0;TP=0;FP=0\n",
    "    for i in range(len(y_predicted)):\n",
    "        y_pred0 = y_predicted[i]\n",
    "        y_true0 = y_true[i]\n",
    "        if y_pred0 == y_true0:\n",
    "            if y_pred0==4:\n",
    "                TP+=1\n",
    "            else:\n",
    "                TN+=1\n",
    "        else:\n",
    "            if y_pred0 == 2:\n",
    "                FN+=1\n",
    "            if y_pred0 == 4:\n",
    "                FP+=1\n",
    "    if prints:\n",
    "        print '======== CONFUSION MATRIX ========'\n",
    "        print '\\t\\tPREDICTED CLASS\\n\\t\\t---------------\\nTRUE CLASS  |  Benign\\tMalignant\\n  Benign    |\\t%i\\t%i\\n  Malignant |\\t%i\\t%i'%(TN,FP,FN,TP)\n",
    "        print '=================================='\n",
    "    return TN,FN,TP,FP\n",
    "            \n",
    "def getMetrics(TN,FN,TP,FP,prints=True):\n",
    "    TN,FN,TP,FP=float(TN),float(FN),float(TP),float(FP)\n",
    "    Acc = (TN+TP)/(TN+TP+FN+FP)\n",
    "    TPR = TP/(TP+FN)\n",
    "    PPV = TP/(TP+FP)\n",
    "    TNR = TN/(TN+FP)\n",
    "    F1  = (2*PPV*TPR)/(PPV+TPR)\n",
    "    if prints:\n",
    "        labels = ['Acc.','TPR','PPV','TNR','F1']\n",
    "        print '====== Performance Metrics ======'\n",
    "        for i in range(len(labels)):\n",
    "            print '\\t%s\\t: %.4f'%(labels[i],metrics[i])\n",
    "        print '================================='\n",
    "    return Acc,TPR,PPV,TNR,F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choosing *k*=3 for optimal nearest-neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dict,y_pred = getNeighbors(x_train,x_test,y_train,y_test,k=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== CONFUSION MATRIX ========\n",
      "\t\tPREDICTED CLASS\n",
      "\t\t---------------\n",
      "TRUE CLASS  |  Benign\tMalignant\n",
      "  Benign    |\t221\t6\n",
      "  Malignant |\t2\t112\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "TN,FN,TP,FP = confusion_matrix(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Performance Metrics ======\n",
      "\tAcc.\t: 0.9765\n",
      "\tTPR\t: 0.9825\n",
      "\tPPV\t: 0.9492\n",
      "\tTNR\t: 0.9736\n",
      "\tF1\t: 0.9655\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "metrics= getMetrics(TN,FN,TP,FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1) Data Analysis - Decision Tree Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decision_tree(object):\n",
    "    \n",
    "    def __init__(self,depth=2):\n",
    "        self.max_depth = depth\n",
    "    \n",
    "    def gini(self,features,classes):\n",
    "        gini_index = 0\n",
    "        for feature in features:\n",
    "            size=len(feature) ; score = 0.0\n",
    "            for class_val in classes:\n",
    "                score += ((feature[:,-1] == class_val).sum()/float(size))**2\n",
    "            gini_index += (1.0-score)*(float(size)/sum([len(feature) for feature in features]))\n",
    "        return gini_index\n",
    "    \n",
    "    def gini_score(self, groups, classes):\n",
    "        n_samples = sum([len(group) for group in groups])\n",
    "        gini = 0\n",
    "        for group in groups:\n",
    "            size = float(len(group))\n",
    "            if size == 0:\n",
    "                continue\n",
    "            score = 0.0\n",
    "            #print(size)\n",
    "            for class_val in classes:\n",
    "                #print(group.shape)\n",
    "                p = (group[:,-1] == class_val).sum() / size\n",
    "                #print(p)\n",
    "                score += p * p\n",
    "            gini += (1.0 - score) * (size / n_samples)\n",
    "            #print(gini)\n",
    "        return gini\n",
    "    \n",
    "    def entropy(self,data_y):\n",
    "        elements,counts = np.unique(data_y,return_counts=True)\n",
    "        en = []\n",
    "        for i in range(len(elements)):\n",
    "            en.append( (-counts[i]/sum(counts))*float(np.log2(counts[i]/sum(counts))) )\n",
    "        return np.sum(en)\n",
    "    \n",
    "    def tree_split(self, feature, value, data):\n",
    "        data_left = np.array([]).reshape(0,self.data.shape[1])\n",
    "        data_right = np.array([]).reshape(0,self.data.shape[1])\n",
    "        for i in data:\n",
    "            if i[feature] <= value:\n",
    "                data_left = np.vstack((data_left,i))\n",
    "            if i[feature] > value:\n",
    "                data_right = np.vstack((data_right,i))\n",
    "        return data_left, data_right\n",
    "\n",
    "    def choose_split(self, data):\n",
    "        classes = np.unique(self.data[:,-1])\n",
    "        best_feat = 999;best_val = 999;best_score = 999;best_groups = None\n",
    "        for feat in range(self.data.shape[1]-1):\n",
    "            for i in data:\n",
    "                features = self.tree_split(feat,i[feat],self.data)\n",
    "                if self.cost_function=='gini':\n",
    "                    value = self.gini_score(np.array(features), classes)\n",
    "                if self.cost_function=='entropy':\n",
    "                    value = self.entropy(self.data_y)\n",
    "                if value < best_score:\n",
    "                    best_feat = feat\n",
    "                    best_val = i[feat]\n",
    "                    best_score = value\n",
    "                    best_groups = groups\n",
    "        output = {}\n",
    "        output['feat'] = best_feat\n",
    "        output['val'] = best_val\n",
    "        output['groups'] = best_groups\n",
    "        return output\n",
    "    \n",
    "    def split_attribute(self,leaf,depth):\n",
    "        left_leaf, right_leaf = leaf['groups']; del(leaf['groups'])\n",
    "        if depth >= self.max_depth:\n",
    "            leaf['left'] = self.terminal_leaf(left_leaf)\n",
    "            leaf['right'] = self.terminal_leaf(right_leaf)\n",
    "            return\n",
    "            \n",
    "    def predict_sample(self, node, sample):\n",
    "        if sample[node['feat']] < node['val']:\n",
    "            if isinstance(node['left'],dict):\n",
    "                return self.predict_sample(node['left'],sample)\n",
    "            else:\n",
    "                return node['left']\n",
    "        else:\n",
    "            if isinstance(node['right'],dict):\n",
    "                return self.predict_sample(node['right'],sample)\n",
    "            else:\n",
    "                return node['right']\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        self.prediction = np.array([])\n",
    "        for i in X_test:\n",
    "            self.prediction = np.append(self.prediction,self.predict_sample(self.root,i))\n",
    "        return self.prediction\n",
    "    ''''''\n",
    "    def best_split(self, Xy):\n",
    "        classes = np.unique(Xy[:,-1])\n",
    "        best_score = 999\n",
    "        for feat in range(Xy.shape[1]-1):\n",
    "            for i in Xy:\n",
    "                groups = self.tree_split(feat, i[feat], Xy)\n",
    "                gini = self.gini_score(groups, classes)\n",
    "                if gini < best_score:\n",
    "                    best_feat = feat\n",
    "                    best_val = i[feat]\n",
    "                    best_score = gini\n",
    "                    best_groups = groups\n",
    "        output = {}\n",
    "        output['feat'] = best_feat\n",
    "        output['val'] = best_val\n",
    "        output['groups'] = best_groups\n",
    "        return output\n",
    "    \n",
    "    def terminal_node(self, group):\n",
    "        # errored out: couldn't np.unique(nothing) or something - doesn't happen all the time\n",
    "        #print(group[:,-1])\n",
    "        classes, counts = np.unique(group[:,-1],return_counts=True)\n",
    "        return classes[np.argmax(counts)]\n",
    "            \n",
    "    def split_branch(self, node, depth):\n",
    "        left_node, right_node = node['groups']\n",
    "        del(node['groups'])\n",
    "        if not isinstance(left_node,np.ndarray) or not isinstance(right_node,np.ndarray):\n",
    "            node['left'] = node['right'] = self.terminal_node(left_node + right_node)\n",
    "            return\n",
    "        if depth >= self.max_depth:\n",
    "            node['left'] = self.terminal_node(left_node)\n",
    "            node['right'] = self.terminal_node(right_node)\n",
    "            return\n",
    "    \n",
    "    def build_tree(self):\n",
    "        '''Recursively build tree, unclear if this is the correct way\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        self.root = self.best_split(self.data)\n",
    "        #print(self.root)\n",
    "        self.split_branch(self.root, 1) # i don't understand how this is working, pointed to node?\n",
    "        #print(self.root)\n",
    "        return self.root\n",
    "    \n",
    "    def train(self,data_x,data_y,cost):\n",
    "        self.cost_function = cost # entropy, gin, or misclassification error\n",
    "        self.data_x = data_x      # numeric values for feature data\n",
    "        self.data_y = data_y      # class values for feature data\n",
    "        self.data = np.column_stack((data_x,data_y)) # creating matrix for training set\n",
    "        self.build_tree()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = decision_tree()\n",
    "dt.train(data_x=X_train,data_y=y_train,cost='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decision_tree(object):\n",
    "    def __init__(self, max_depth,min_num_sample):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_num_sample = min_num_sample\n",
    "    \n",
    "    \n",
    "    def gini(self, groups, classes):\n",
    "        n_samples = sum([len(group) for group in groups])\n",
    "        gini = 0\n",
    "        for group in groups:\n",
    "            size = float(len(group))\n",
    "            if size == 0:\n",
    "                continue\n",
    "            score = 0.0\n",
    "            for class_val in classes:\n",
    "                score += np.power((group[:,-1] == class_val).sum() / size,2)\n",
    "            gini += (1.0-score)*(size/sum([len(group) for group in groups]))\n",
    "        return gini\n",
    "    \n",
    "    def tree_split(self, feat, val, data):\n",
    "        Xi_left = np.array([]).reshape(0,self.data.shape[1])\n",
    "        Xi_right = np.array([]).reshape(0,self.data.shape[1])\n",
    "        for i in self.data:\n",
    "            if i[feat] <= val:\n",
    "                Xi_left = np.vstack((Xi_left,i))\n",
    "            if i[feat] > val:\n",
    "                Xi_right = np.vstack((Xi_right,i))\n",
    "        return Xi_left, Xi_right\n",
    "    \n",
    "    def best_split(self, data):\n",
    "        classes = np.unique(self.data[:,-1])\n",
    "        best_score = 999\n",
    "        for feat in range(self.data.shape[1]-1):\n",
    "            for i in self.data:\n",
    "                groups = self.tree_split(feat, i[feat], self.data)\n",
    "                gini = self.gini(groups, classes)\n",
    "                if gini < best_score:\n",
    "                    best_feat = feat\n",
    "                    best_val = i[feat]\n",
    "                    best_score = gini\n",
    "                    best_groups = groups\n",
    "        output = {}\n",
    "        output['feat'] = best_feat\n",
    "        output['val'] = best_val\n",
    "        output['groups'] = best_groups\n",
    "        return output\n",
    "    \n",
    "    def terminal_node(self, group):\n",
    "        classes, counts = np.unique(group[:,-1],return_counts=True)\n",
    "        return classes[np.argmax(counts)]\n",
    "            \n",
    "    def split_branch(self, node, depth):\n",
    "        left_node, right_node = node['groups']\n",
    "        del(node['groups'])\n",
    "        if not isinstance(left_node,np.ndarray) or not isinstance(right_node,np.ndarray):\n",
    "            node['left'] = node['right'] = self.terminal_node(left_node + right_node)\n",
    "            return\n",
    "        if depth >= self.max_depth:\n",
    "            node['left'] = self.terminal_node(left_node)\n",
    "            node['right'] = self.terminal_node(right_node)\n",
    "            return\n",
    "        if len(left_node) <= self.min_num_sample:\n",
    "            node['left'] = self.terminal_node(left_node)\n",
    "        else:\n",
    "            node['left'] = self.best_split(left_node)\n",
    "            self.split_branch(node['left'], depth+1)\n",
    "        if len(right_node) <= self.min_num_sample:\n",
    "            node['right'] = self.terminal_node(right_node)\n",
    "        else:\n",
    "            node['right'] = self.best_split(right_node)\n",
    "            self.split_branch(node['right'], depth+1)\n",
    "    \n",
    "    def build_tree(self):\n",
    "        self.root = self.best_split(self.data)\n",
    "        self.split_branch(self.root, 1)\n",
    "        return self.root\n",
    "    \n",
    "    def train(self,data_x,data_y):\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.data = np.column_stack((data_x,data_y))\n",
    "        self.root = self.best_split(self.data)\n",
    "        self.split_branch(self.root, 1)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        self.y_pred = np.array([])\n",
    "        for i in X_test:\n",
    "            self.y_pred = np.append(self.y_pred,self.predict_sample(self.root,i))\n",
    "        return self.y_pred\n",
    "    \n",
    "    def predict_sample(self, node, sample):\n",
    "        if sample[node['feat']] < node['val']:\n",
    "            if isinstance(node['left'],dict):\n",
    "                return self.predict_sample(node['left'],sample)\n",
    "            else:\n",
    "                return node['left']\n",
    "        else:\n",
    "            if isinstance(node['right'],dict):\n",
    "                return self.predict_sample(node['right'],sample)\n",
    "            else:\n",
    "                return node['right']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = decision_tree(max_depth=2,min_num_sample=20)\n",
    "dt.train(X_train,y_train)\n",
    "my_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 2., 4., 4., 4., 4., 4., 2., 4., 2., 4., 2., 4., 2., 4., 2., 2.,\n",
       "       4., 2., 2., 4., 2., 2., 4., 4., 4., 4., 2., 4., 4., 2., 2., 2., 4.,\n",
       "       4., 2., 4., 2., 2., 2., 4., 2., 4., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 4., 4., 4., 4., 4., 2., 4., 2., 2., 2., 2., 4., 2., 2., 2.,\n",
       "       4., 4., 4., 4., 2., 2., 2., 2., 4., 4., 4., 2., 2., 4., 2., 2., 4.,\n",
       "       2., 4., 2., 4., 2., 4., 2., 4., 2., 4., 2., 4., 4., 4., 4., 2., 2.,\n",
       "       4., 4., 2., 4., 2., 2., 2., 2., 2., 4., 2., 2., 2., 4., 2., 4., 4.,\n",
       "       2., 4., 2., 2., 2., 4., 4., 2., 2., 2., 2., 2., 4., 4., 2., 2., 2.,\n",
       "       2., 2., 4., 2., 4., 2., 2., 4., 2., 2., 2., 2., 4., 2., 2., 2., 4.,\n",
       "       4., 2., 2., 4., 4., 4., 2., 2., 2., 4., 2., 4., 4., 2., 4., 2., 4.,\n",
       "       2.])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.root\n",
    "my_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
