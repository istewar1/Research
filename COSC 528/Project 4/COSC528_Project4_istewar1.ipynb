{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Title***: Project 4 - *Artificial Neural Network for Email Spam data*\n",
    "## ***Author***: Ian R. Stewart\n",
    "## ***Course***: COSC528 : Fall 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random # Using to randomize initial weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### **IMPORTING DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inPath = '/Users/i6o/Research/COSC 528/Project 4/'\n",
    "inPath = './'\n",
    "outPath = inPath+'Figures/'\n",
    "features = ['word_freq_make','word_freq_address','word_freq_all','word_freq_3d','word_freq_our','word_freq_over','word_freq_remove','word_freq_internet','word_freq_order','word_freq_mail','word_freq_receive','word_freq_will','word_freq_people','word_freq_report','word_freq_addresses','word_freq_free','word_freq_business','word_freq_email','word_freq_you','word_freq_credit','word_freq_your','word_freq_font','word_freq_000','word_freq_money','word_freq_hp','word_freq_hpl','word_freq_george','word_freq_650','word_freq_lab','word_freq_labs','word_freq_telnet','word_freq_857','word_freq_data','word_freq_415','word_freq_85','word_freq_technology','word_freq_1999','word_freq_parts','word_freq_pm','word_freq_direct','word_freq_cs','word_freq_meeting','word_freq_original','word_freq_project','word_freq_re','word_freq_edu','word_freq_table','word_freq_conference','char_freq_;','char_freq_(','char_freq_[','char_freq_!','char_freq_$','char_freq_#','capital_run_length_average','capital_run_length_longest','capital_run_length_total','spam class']\n",
    "df = pd.read_csv(inPath+'spambase.data',names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0             0.0               0.64           0.64           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32             0.0               0.0                 0.0   \n",
       "\n",
       "   word_freq_order  word_freq_mail     ...      char_freq_;  char_freq_(  \\\n",
       "0              0.0             0.0     ...              0.0          0.0   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778          0.0          0.0   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "\n",
       "   capital_run_length_total  spam class  \n",
       "0                       278           1  \n",
       "\n",
       "[1 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape:\t(4601,58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5.19</td>\n",
       "      <td>52.17</td>\n",
       "      <td>283.29</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.31</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>31.73</td>\n",
       "      <td>194.89</td>\n",
       "      <td>606.35</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.59</td>\n",
       "      <td>6.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.28</td>\n",
       "      <td>15.00</td>\n",
       "      <td>95.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.71</td>\n",
       "      <td>43.00</td>\n",
       "      <td>266.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.54</td>\n",
       "      <td>14.28</td>\n",
       "      <td>5.10</td>\n",
       "      <td>42.81</td>\n",
       "      <td>10.00</td>\n",
       "      <td>5.88</td>\n",
       "      <td>7.27</td>\n",
       "      <td>11.11</td>\n",
       "      <td>5.26</td>\n",
       "      <td>18.18</td>\n",
       "      <td>...</td>\n",
       "      <td>4.38</td>\n",
       "      <td>9.75</td>\n",
       "      <td>4.08</td>\n",
       "      <td>32.48</td>\n",
       "      <td>6.00</td>\n",
       "      <td>19.83</td>\n",
       "      <td>1102.50</td>\n",
       "      <td>9989.00</td>\n",
       "      <td>15841.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "count         4601.00            4601.00        4601.00       4601.00   \n",
       "mean             0.10               0.21           0.28          0.07   \n",
       "std              0.31               1.29           0.50          1.40   \n",
       "min              0.00               0.00           0.00          0.00   \n",
       "25%              0.00               0.00           0.00          0.00   \n",
       "50%              0.00               0.00           0.00          0.00   \n",
       "75%              0.00               0.00           0.42          0.00   \n",
       "max              4.54              14.28           5.10         42.81   \n",
       "\n",
       "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "count        4601.00         4601.00           4601.00             4601.00   \n",
       "mean            0.31            0.10              0.11                0.11   \n",
       "std             0.67            0.27              0.39                0.40   \n",
       "min             0.00            0.00              0.00                0.00   \n",
       "25%             0.00            0.00              0.00                0.00   \n",
       "50%             0.00            0.00              0.00                0.00   \n",
       "75%             0.38            0.00              0.00                0.00   \n",
       "max            10.00            5.88              7.27               11.11   \n",
       "\n",
       "       word_freq_order  word_freq_mail     ...      char_freq_;  char_freq_(  \\\n",
       "count          4601.00         4601.00     ...          4601.00      4601.00   \n",
       "mean              0.09            0.24     ...             0.04         0.14   \n",
       "std               0.28            0.64     ...             0.24         0.27   \n",
       "min               0.00            0.00     ...             0.00         0.00   \n",
       "25%               0.00            0.00     ...             0.00         0.00   \n",
       "50%               0.00            0.00     ...             0.00         0.06   \n",
       "75%               0.00            0.16     ...             0.00         0.19   \n",
       "max               5.26           18.18     ...             4.38         9.75   \n",
       "\n",
       "       char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "count      4601.00      4601.00      4601.00      4601.00   \n",
       "mean          0.02         0.27         0.08         0.04   \n",
       "std           0.11         0.82         0.25         0.43   \n",
       "min           0.00         0.00         0.00         0.00   \n",
       "25%           0.00         0.00         0.00         0.00   \n",
       "50%           0.00         0.00         0.00         0.00   \n",
       "75%           0.00         0.32         0.05         0.00   \n",
       "max           4.08        32.48         6.00        19.83   \n",
       "\n",
       "       capital_run_length_average  capital_run_length_longest  \\\n",
       "count                     4601.00                     4601.00   \n",
       "mean                         5.19                       52.17   \n",
       "std                         31.73                      194.89   \n",
       "min                          1.00                        1.00   \n",
       "25%                          1.59                        6.00   \n",
       "50%                          2.28                       15.00   \n",
       "75%                          3.71                       43.00   \n",
       "max                       1102.50                     9989.00   \n",
       "\n",
       "       capital_run_length_total  spam class  \n",
       "count                   4601.00     4601.00  \n",
       "mean                     283.29        0.39  \n",
       "std                      606.35        0.49  \n",
       "min                        1.00        0.00  \n",
       "25%                       35.00        0.00  \n",
       "50%                       95.00        0.00  \n",
       "75%                      266.00        1.00  \n",
       "max                    15841.00        1.00  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'dataframe shape:\\t(%i,%i)'%(df.shape[0],df.shape[1])\n",
    "np.round(df.describe(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Checking for empty arrays in matrix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO MISSING DATA IN DATAFRAME.\n"
     ]
    }
   ],
   "source": [
    "# Iterating through df, searching for .isnull().any()\n",
    "count = 0; indexes = []\n",
    "for i in df.isnull().any():\n",
    "    if i == True:\n",
    "        indexes.append(count)\n",
    "    count+=1\n",
    "if len(indexes)>0:\n",
    "    print 'FEATURES WITH MISSING DATA: %s'%df.columns.values[indexes]\n",
    "else:\n",
    "    print 'NO MISSING DATA IN DATAFRAME.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for negative values in dataset\n",
    "for i in df:\n",
    "    [j for j in df[i] if j < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NO EMPTY data entries or NEGATIVE values in columns. Now, let's examine the data types for each data feature (column)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 58 columns):\n",
      "word_freq_make                4601 non-null float64\n",
      "word_freq_address             4601 non-null float64\n",
      "word_freq_all                 4601 non-null float64\n",
      "word_freq_3d                  4601 non-null float64\n",
      "word_freq_our                 4601 non-null float64\n",
      "word_freq_over                4601 non-null float64\n",
      "word_freq_remove              4601 non-null float64\n",
      "word_freq_internet            4601 non-null float64\n",
      "word_freq_order               4601 non-null float64\n",
      "word_freq_mail                4601 non-null float64\n",
      "word_freq_receive             4601 non-null float64\n",
      "word_freq_will                4601 non-null float64\n",
      "word_freq_people              4601 non-null float64\n",
      "word_freq_report              4601 non-null float64\n",
      "word_freq_addresses           4601 non-null float64\n",
      "word_freq_free                4601 non-null float64\n",
      "word_freq_business            4601 non-null float64\n",
      "word_freq_email               4601 non-null float64\n",
      "word_freq_you                 4601 non-null float64\n",
      "word_freq_credit              4601 non-null float64\n",
      "word_freq_your                4601 non-null float64\n",
      "word_freq_font                4601 non-null float64\n",
      "word_freq_000                 4601 non-null float64\n",
      "word_freq_money               4601 non-null float64\n",
      "word_freq_hp                  4601 non-null float64\n",
      "word_freq_hpl                 4601 non-null float64\n",
      "word_freq_george              4601 non-null float64\n",
      "word_freq_650                 4601 non-null float64\n",
      "word_freq_lab                 4601 non-null float64\n",
      "word_freq_labs                4601 non-null float64\n",
      "word_freq_telnet              4601 non-null float64\n",
      "word_freq_857                 4601 non-null float64\n",
      "word_freq_data                4601 non-null float64\n",
      "word_freq_415                 4601 non-null float64\n",
      "word_freq_85                  4601 non-null float64\n",
      "word_freq_technology          4601 non-null float64\n",
      "word_freq_1999                4601 non-null float64\n",
      "word_freq_parts               4601 non-null float64\n",
      "word_freq_pm                  4601 non-null float64\n",
      "word_freq_direct              4601 non-null float64\n",
      "word_freq_cs                  4601 non-null float64\n",
      "word_freq_meeting             4601 non-null float64\n",
      "word_freq_original            4601 non-null float64\n",
      "word_freq_project             4601 non-null float64\n",
      "word_freq_re                  4601 non-null float64\n",
      "word_freq_edu                 4601 non-null float64\n",
      "word_freq_table               4601 non-null float64\n",
      "word_freq_conference          4601 non-null float64\n",
      "char_freq_;                   4601 non-null float64\n",
      "char_freq_(                   4601 non-null float64\n",
      "char_freq_[                   4601 non-null float64\n",
      "char_freq_!                   4601 non-null float64\n",
      "char_freq_$                   4601 non-null float64\n",
      "char_freq_#                   4601 non-null float64\n",
      "capital_run_length_average    4601 non-null float64\n",
      "capital_run_length_longest    4601 non-null int64\n",
      "capital_run_length_total      4601 non-null int64\n",
      "spam class                    4601 non-null int64\n",
      "dtypes: float64(55), int64(3)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**All features are either float64 or int64, which is ideal as an object return would require further investigation into the data feature to track down why Python is reading the column as a non-float or -int.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **After initial pruning of the data, I observed an odd behaviour where the majority of the data entries examined (at random) contained a 1.0 spam classification indicating that the email was, in fact, spam. I want to plot the data to look if all the data are in fact spam.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Entry Index in Dataframe')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x320 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(dpi=80)\n",
    "ax.plot(df['spam class'].values,'ro--',linewidth=1,markersize=5)\n",
    "ax.grid(alpha=0.5)\n",
    "ax.set_ylabel('Binary Spam Classification Value')\n",
    "ax.set_xlabel('Entry Index in Dataframe')\n",
    "#plt.savefig(outPath+'Initial_Classification_Investigation.png',dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **My hypothesis failed, where all data entries are assigned to one class (spam or non-spam). Let's count the spam classifications.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[No. of Spam , No. of non-Spam]\t :  [2788 , 1813]\n"
     ]
    }
   ],
   "source": [
    "print '[No. of Spam , No. of non-Spam]\\t :  [%i , %i]'%(list(df['spam class']).count(0),list(df['spam class']).count(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **This shows that ~40% (1813/4601) of the data are classified as SPAM with the remaining ~60% (2788/4601) being non-SPAM. Another observation is that the classifications are actually grouped together, where the SPAM classifications are the FIRST 1813 entries and the latter portion of the dataframe are ALL non-SPAM classifications. This is an interesting finding, as a small training-test split for a cross-validation study can potentially cause classification errors if the an sufficient amount of each group is not represented in the training set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating training-test split function for cross-validation study later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(data_x,data_y,n):\n",
    "    '''\n",
    "    :param data_x : {array} feature data\n",
    "    :param data_y : {array} classificatin data\n",
    "    :param n      : {int}   percentage of split in training\n",
    "    '''\n",
    "    data_x = np.asarray(data_x)\n",
    "    length_test = int(round(len(data_x)*(n/100.)))\n",
    "    # Create random integers between two numbers with no repeats\n",
    "    train_list = random.sample(range(0,len(data_x)), length_test)\n",
    "    train_list.sort()\n",
    "    test_list = np.arange(0,len(data_x))\n",
    "    test_list = np.delete(test_list,train_list)\n",
    "    data_y = np.array(data_y)\n",
    "    x_train,y_train = np.array(data_x[train_list]),np.array(data_y[train_list])\n",
    "    x_test,y_test   = np.array(data_x[test_list]),np.array(data_y[test_list])\n",
    "    \n",
    "    return (x_train,x_test,y_train,y_test,train_list,list(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN():\n",
    "    '''\n",
    "    ANN : artificial neural network\n",
    "    Description: The general flow of this ANN class is as follows:\n",
    "            1. Split data into Training and Test set\n",
    "        On training data, perform:\n",
    "            2. Initialize weights for given number of hidden layers\n",
    "            3. Forward propagate and calc output\n",
    "                a. activiation step\n",
    "                b. neuron transfer step\n",
    "                c. forward propagation step\n",
    "            4. \n",
    "    '''\n",
    "    def __init__(self,n_inputs,n_hidden,n_neurons,n_outputs,activation_func):\n",
    "        self.n_inputs  = 57\n",
    "        self.n_hidden  = 1\n",
    "        self.n_neurons = 5\n",
    "        self.n_outputs = 2\n",
    "        self.activation_func = 'sigmoid'\n",
    "        if (activation_func!='sigmoid')or(activation_func!='linear')or(activation_func!='softmax'):\n",
    "            print 'CHOOSE CORRECT ACTIVIATION FUNCTION FROM LIST:\\n1.\\tsigmoid\\n2.\\tlinear\\n3.\\tsoftmax'\n",
    "      \n",
    "    def test_split(self,data_x,data_y,n):\n",
    "        '''\n",
    "        :param data_x : { array } feature data\n",
    "        :param data_y : { array } classificatin data\n",
    "        :param n      : { int   } percentage of split in training\n",
    "        '''\n",
    "        data_x = np.asarray(data_x)\n",
    "        length_test = int(round(len(data_x)*(n/100.)))\n",
    "        # Create random integers between two numbers with no repeats\n",
    "        train_list = random.sample(range(0,len(data_x)), length_test)\n",
    "        train_list.sort()\n",
    "        test_list = np.arange(0,len(data_x))\n",
    "        test_list = np.delete(test_list,train_list)\n",
    "        data_y = np.array(data_y)\n",
    "        x_train,y_train = np.array(data_x[train_list]),np.array(data_y[train_list])\n",
    "        x_test,y_test   = np.array(data_x[test_list]),np.array(data_y[test_list])\n",
    "        return (x_train,x_test,y_train,y_test,train_list,list(test_list))\n",
    "\n",
    "    def initialize(self,number_inputs,number_hidden,number_neurons,number_outputs):\n",
    "        '''\n",
    "        Description : Initialize weights for constructed network. Weight values for the \n",
    "                        hidden layer weights contain a +1 value to account for the bias \n",
    "                        at each layer.\n",
    "        \n",
    "        :param number_inputs  : { int } number of inputs in input layer\n",
    "        :param number_hidden  : { int } number of hidden layers in network\n",
    "        :param number_neurons : { int } number of neurons in hidden layer\n",
    "        :param number_outputs : { int } number of outputs in output layer\n",
    "        '''\n",
    "        network = []\n",
    "        for i in range(number_hidden):\n",
    "            # empty, initialize network\n",
    "            if i==0:\n",
    "                hidden_layer = [{'weights':[random.uniform(0, 1) for i in range(number_inputs + 1)]} for i in range(number_neurons)]\n",
    "                network.append(hidden_layer) \n",
    "            # append after initializations\n",
    "            else:\n",
    "                hidden_layer = [{'weights':[random.uniform(0, 1) for i in range(number_neurons + 1)]} for i in range(number_neurons)]\n",
    "                network.append(hidden_layer)\n",
    "        output_layer = [{'weights':[random.uniform(0, 1) for i in range(number_neurons + 1)]} for i in range(number_outputs)]\n",
    "        network.append(output_layer)\n",
    "        return self.network\n",
    "    \n",
    "    def activate(self,weights, inputs):\n",
    "        '''\n",
    "        activate : neuron activation function calculated\n",
    "                    by the weighted sum of inputs plus bias.\n",
    "                    Bias is positioned to final value in the list.\n",
    "        '''\n",
    "        activation = weights[-1] # initialize \n",
    "        for i in range(len(weights)-1):\n",
    "            activation += weights[i] * inputs[i]\n",
    "        return activation\n",
    "\n",
    "    def transfer_function(self,a):\n",
    "        if (self.activation_func=='sigmoid') or (self.activation_func=='logistic sigmoid'):\n",
    "            return (1.0 + np.exp(-a))**-1\n",
    "        if self.activation_func=='linear':\n",
    "            return a\n",
    "        if self.activation_func=='softmax':\n",
    "            return 1.0 / (1.0 + exp(-a))\n",
    "\n",
    "    # Forward propagate input to a network output\n",
    "    def forward(self,network, row):\n",
    "        inputs = row\n",
    "        for layer in network:\n",
    "            new_inputs = []\n",
    "            for neuron in layer:\n",
    "                activation = activate(neuron['weights'], inputs)\n",
    "                neuron['output'] = transfer_function(activation)\n",
    "                new_inputs.append(neuron['output'])\n",
    "            inputs = new_inputs\n",
    "        return inputs\n",
    "    \n",
    "    def backward(network,known):\n",
    "        for i in range(len(network))[::-1]:\n",
    "            layer = network[i]\n",
    "            errors = list()\n",
    "            if i != len(network)-1:\n",
    "                for j in range(len(layer)):\n",
    "                    error = 0.0\n",
    "                    for neuron in network[i + 1]:\n",
    "                        error += (neuron['weights'][j] * neuron['delta'])\n",
    "                    errors.append(error)\n",
    "            else:\n",
    "                for j in range(len(layer)):\n",
    "                    neuron = layer[j]\n",
    "                    errors.append(expected[j] - neuron['output'])\n",
    "            for j in range(len(layer)):\n",
    "                neuron = layer[j]\n",
    "                neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
    "    \n",
    "    def main(self,data,split,n_inputs,n_hidden,n_outputs):\n",
    "        '''\n",
    "        main : runs ANN with provided network structure\n",
    "        '''\n",
    "        \n",
    "        network = initialize(n_inputs,n_hidden,n_outputs)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def transfer_function(a):\n",
    "    return (1.0 + np.exp(-a))**-1\n",
    "\n",
    "def backward_propagate_error(network, expected):\n",
    "\tfor i in reversed(range(len(network))):\n",
    "\t\tlayer = network[i]\n",
    "\t\terrors = list()\n",
    "\t\tif i != len(network)-1:\n",
    "\t\t\tfor j in range(len(layer)):\n",
    "\t\t\t\terror = 0.0\n",
    "\t\t\t\tfor neuron in network[i + 1]:\n",
    "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
    "\t\t\t\terrors.append(error)\n",
    "\t\telse:\n",
    "\t\t\tfor j in range(len(layer)):\n",
    "\t\t\t\tneuron = layer[j]\n",
    "\t\t\t\terrors.append(expected[j] - neuron['output'])\n",
    "\t\tfor j in range(len(layer)):\n",
    "\t\t\tneuron = layer[j]\n",
    "\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.90638072270967318, 0.76610003734280829]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = [\n",
    "        [\n",
    "        {'weights': [0.7270700037509241, 0.7383627445080684, 0.18978193074880423]}, \n",
    "        {'weights': [0.7869285898008361, 0.11191242288793657, 0.6323166547815777]}, \n",
    "        {'weights': [0.5542929997136264, 0.6299108552149877, 0.036872224253109986]}\n",
    "        ],\n",
    "        [\n",
    "        {'weights': [0.9541070703271004, 0.9002708967220981, 0.5574211004774138, 0.56239456051497]}, \n",
    "        {'weights': [0.5772579431172555, 0.5744375394342741, 0.276212229019259, 0.5615663370673547]}, \n",
    "        {'weights': [0.49917371980390934, 0.2289715704548373, 0.9165265896818503, 0.4831653543316994]}\n",
    "        ],\n",
    "        [\n",
    "        {'weights': [0.7936276360327776, 0.9247539681130554, 0.08899479960010304, 0.6728626611317721]}, \n",
    "        {'weights': [0.19170994036771682, 0.8864472297353635, 0.1201225021016884, 0.15257603530797048]}\n",
    "        ]\n",
    "            ]\n",
    "forward_propagate(network,[1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK: Original data shape of (4601,58) and splits shapes:\n",
      "\tx_data:\t(4601,57)\n",
      "\ty_data:\t(4601,1)\n"
     ]
    }
   ],
   "source": [
    "y_data = np.array(df.iloc[:,-1])\n",
    "x_data = np.array(df.iloc[:,0:-1])\n",
    "print 'CHECK: Original data shape of (%i,%i) and splits shapes:\\n\\tx_data:\\t(%i,%i)\\n\\ty_data:\\t(%i,1)'\\\n",
    "    %(df.shape[0],df.shape[1],x_data.shape[0],x_data.shape[1],y_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
