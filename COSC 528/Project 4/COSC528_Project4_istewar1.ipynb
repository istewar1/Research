{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Title***: Project 4 - *Artificial Neural Network for Email Spam data*\n",
    "## ***Author***: Ian R. Stewart\n",
    "## ***Course***: COSC528 : Fall 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random # Using to randomize initial weights\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### **IMPORTING DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inPath = './'\n",
    "outPath = inPath+'Figures/'\n",
    "features = ['word_freq_make','word_freq_address','word_freq_all','word_freq_3d','word_freq_our','word_freq_over','word_freq_remove','word_freq_internet','word_freq_order','word_freq_mail','word_freq_receive','word_freq_will','word_freq_people','word_freq_report','word_freq_addresses','word_freq_free','word_freq_business','word_freq_email','word_freq_you','word_freq_credit','word_freq_your','word_freq_font','word_freq_000','word_freq_money','word_freq_hp','word_freq_hpl','word_freq_george','word_freq_650','word_freq_lab','word_freq_labs','word_freq_telnet','word_freq_857','word_freq_data','word_freq_415','word_freq_85','word_freq_technology','word_freq_1999','word_freq_parts','word_freq_pm','word_freq_direct','word_freq_cs','word_freq_meeting','word_freq_original','word_freq_project','word_freq_re','word_freq_edu','word_freq_table','word_freq_conference','char_freq_;','char_freq_(','char_freq_[','char_freq_!','char_freq_$','char_freq_#','capital_run_length_average','capital_run_length_longest','capital_run_length_total','spam class']\n",
    "df = pd.read_csv(inPath+'spambase.data',names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0             0.0               0.64           0.64           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32             0.0               0.0                 0.0   \n",
       "\n",
       "   word_freq_order  word_freq_mail     ...      char_freq_;  char_freq_(  \\\n",
       "0              0.0             0.0     ...              0.0          0.0   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778          0.0          0.0   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "\n",
       "   capital_run_length_total  spam class  \n",
       "0                       278           1  \n",
       "\n",
       "[1 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape:\t(4601,58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "      <td>4601.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5.19</td>\n",
       "      <td>52.17</td>\n",
       "      <td>283.29</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.31</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>31.73</td>\n",
       "      <td>194.89</td>\n",
       "      <td>606.35</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.59</td>\n",
       "      <td>6.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.28</td>\n",
       "      <td>15.00</td>\n",
       "      <td>95.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.71</td>\n",
       "      <td>43.00</td>\n",
       "      <td>266.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.54</td>\n",
       "      <td>14.28</td>\n",
       "      <td>5.10</td>\n",
       "      <td>42.81</td>\n",
       "      <td>10.00</td>\n",
       "      <td>5.88</td>\n",
       "      <td>7.27</td>\n",
       "      <td>11.11</td>\n",
       "      <td>5.26</td>\n",
       "      <td>18.18</td>\n",
       "      <td>...</td>\n",
       "      <td>4.38</td>\n",
       "      <td>9.75</td>\n",
       "      <td>4.08</td>\n",
       "      <td>32.48</td>\n",
       "      <td>6.00</td>\n",
       "      <td>19.83</td>\n",
       "      <td>1102.50</td>\n",
       "      <td>9989.00</td>\n",
       "      <td>15841.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "count         4601.00            4601.00        4601.00       4601.00   \n",
       "mean             0.10               0.21           0.28          0.07   \n",
       "std              0.31               1.29           0.50          1.40   \n",
       "min              0.00               0.00           0.00          0.00   \n",
       "25%              0.00               0.00           0.00          0.00   \n",
       "50%              0.00               0.00           0.00          0.00   \n",
       "75%              0.00               0.00           0.42          0.00   \n",
       "max              4.54              14.28           5.10         42.81   \n",
       "\n",
       "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "count        4601.00         4601.00           4601.00             4601.00   \n",
       "mean            0.31            0.10              0.11                0.11   \n",
       "std             0.67            0.27              0.39                0.40   \n",
       "min             0.00            0.00              0.00                0.00   \n",
       "25%             0.00            0.00              0.00                0.00   \n",
       "50%             0.00            0.00              0.00                0.00   \n",
       "75%             0.38            0.00              0.00                0.00   \n",
       "max            10.00            5.88              7.27               11.11   \n",
       "\n",
       "       word_freq_order  word_freq_mail     ...      char_freq_;  char_freq_(  \\\n",
       "count          4601.00         4601.00     ...          4601.00      4601.00   \n",
       "mean              0.09            0.24     ...             0.04         0.14   \n",
       "std               0.28            0.64     ...             0.24         0.27   \n",
       "min               0.00            0.00     ...             0.00         0.00   \n",
       "25%               0.00            0.00     ...             0.00         0.00   \n",
       "50%               0.00            0.00     ...             0.00         0.06   \n",
       "75%               0.00            0.16     ...             0.00         0.19   \n",
       "max               5.26           18.18     ...             4.38         9.75   \n",
       "\n",
       "       char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "count      4601.00      4601.00      4601.00      4601.00   \n",
       "mean          0.02         0.27         0.08         0.04   \n",
       "std           0.11         0.82         0.25         0.43   \n",
       "min           0.00         0.00         0.00         0.00   \n",
       "25%           0.00         0.00         0.00         0.00   \n",
       "50%           0.00         0.00         0.00         0.00   \n",
       "75%           0.00         0.32         0.05         0.00   \n",
       "max           4.08        32.48         6.00        19.83   \n",
       "\n",
       "       capital_run_length_average  capital_run_length_longest  \\\n",
       "count                     4601.00                     4601.00   \n",
       "mean                         5.19                       52.17   \n",
       "std                         31.73                      194.89   \n",
       "min                          1.00                        1.00   \n",
       "25%                          1.59                        6.00   \n",
       "50%                          2.28                       15.00   \n",
       "75%                          3.71                       43.00   \n",
       "max                       1102.50                     9989.00   \n",
       "\n",
       "       capital_run_length_total  spam class  \n",
       "count                   4601.00     4601.00  \n",
       "mean                     283.29        0.39  \n",
       "std                      606.35        0.49  \n",
       "min                        1.00        0.00  \n",
       "25%                       35.00        0.00  \n",
       "50%                       95.00        0.00  \n",
       "75%                      266.00        1.00  \n",
       "max                    15841.00        1.00  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'dataframe shape:\\t(%i,%i)'%(df.shape[0],df.shape[1])\n",
    "np.round(df.describe(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Checking for empty arrays in matrix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO MISSING DATA IN DATAFRAME.\n"
     ]
    }
   ],
   "source": [
    "# Iterating through df, searching for .isnull().any()\n",
    "count = 0; indexes = []\n",
    "for i in df.isnull().any():\n",
    "    if i == True:\n",
    "        indexes.append(count)\n",
    "    count+=1\n",
    "if len(indexes)>0:\n",
    "    print 'FEATURES WITH MISSING DATA: %s'%df.columns.values[indexes]\n",
    "else:\n",
    "    print 'NO MISSING DATA IN DATAFRAME.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for negative values in dataset\n",
    "for i in df:\n",
    "    [j for j in df[i] if j < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NO EMPTY data entries or NEGATIVE values in columns. Now, let's examine the data types for each data feature (column)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 58 columns):\n",
      "word_freq_make                4601 non-null float64\n",
      "word_freq_address             4601 non-null float64\n",
      "word_freq_all                 4601 non-null float64\n",
      "word_freq_3d                  4601 non-null float64\n",
      "word_freq_our                 4601 non-null float64\n",
      "word_freq_over                4601 non-null float64\n",
      "word_freq_remove              4601 non-null float64\n",
      "word_freq_internet            4601 non-null float64\n",
      "word_freq_order               4601 non-null float64\n",
      "word_freq_mail                4601 non-null float64\n",
      "word_freq_receive             4601 non-null float64\n",
      "word_freq_will                4601 non-null float64\n",
      "word_freq_people              4601 non-null float64\n",
      "word_freq_report              4601 non-null float64\n",
      "word_freq_addresses           4601 non-null float64\n",
      "word_freq_free                4601 non-null float64\n",
      "word_freq_business            4601 non-null float64\n",
      "word_freq_email               4601 non-null float64\n",
      "word_freq_you                 4601 non-null float64\n",
      "word_freq_credit              4601 non-null float64\n",
      "word_freq_your                4601 non-null float64\n",
      "word_freq_font                4601 non-null float64\n",
      "word_freq_000                 4601 non-null float64\n",
      "word_freq_money               4601 non-null float64\n",
      "word_freq_hp                  4601 non-null float64\n",
      "word_freq_hpl                 4601 non-null float64\n",
      "word_freq_george              4601 non-null float64\n",
      "word_freq_650                 4601 non-null float64\n",
      "word_freq_lab                 4601 non-null float64\n",
      "word_freq_labs                4601 non-null float64\n",
      "word_freq_telnet              4601 non-null float64\n",
      "word_freq_857                 4601 non-null float64\n",
      "word_freq_data                4601 non-null float64\n",
      "word_freq_415                 4601 non-null float64\n",
      "word_freq_85                  4601 non-null float64\n",
      "word_freq_technology          4601 non-null float64\n",
      "word_freq_1999                4601 non-null float64\n",
      "word_freq_parts               4601 non-null float64\n",
      "word_freq_pm                  4601 non-null float64\n",
      "word_freq_direct              4601 non-null float64\n",
      "word_freq_cs                  4601 non-null float64\n",
      "word_freq_meeting             4601 non-null float64\n",
      "word_freq_original            4601 non-null float64\n",
      "word_freq_project             4601 non-null float64\n",
      "word_freq_re                  4601 non-null float64\n",
      "word_freq_edu                 4601 non-null float64\n",
      "word_freq_table               4601 non-null float64\n",
      "word_freq_conference          4601 non-null float64\n",
      "char_freq_;                   4601 non-null float64\n",
      "char_freq_(                   4601 non-null float64\n",
      "char_freq_[                   4601 non-null float64\n",
      "char_freq_!                   4601 non-null float64\n",
      "char_freq_$                   4601 non-null float64\n",
      "char_freq_#                   4601 non-null float64\n",
      "capital_run_length_average    4601 non-null float64\n",
      "capital_run_length_longest    4601 non-null int64\n",
      "capital_run_length_total      4601 non-null int64\n",
      "spam class                    4601 non-null int64\n",
      "dtypes: float64(55), int64(3)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**All features are either float64 or int64, which is ideal as an object return would require further investigation into the data feature to track down why Python is reading the column as a non-float or -int.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **After initial pruning of the data, I observed an odd behaviour where the majority of the data entries examined (at random) contained a 1.0 spam classification indicating that the email was, in fact, spam. I want to plot the data to look if all the data are in fact spam.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Entry Index in Dataframe')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x320 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(dpi=80)\n",
    "ax.plot(df['spam class'].values,'ro--',linewidth=1,markersize=5)\n",
    "ax.grid(alpha=0.5)\n",
    "ax.set_ylabel('Binary Spam Classification Value')\n",
    "ax.set_xlabel('Entry Index in Dataframe')\n",
    "#plt.savefig(outPath+'Initial_Classification_Investigation.png',dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **My hypothesis failed, where all data entries are assigned to one class (spam or non-spam). Let's count the spam classifications.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[No. of Spam , No. of non-Spam]\t :  [2788 , 1813]\n"
     ]
    }
   ],
   "source": [
    "print '[No. of Spam , No. of non-Spam]\\t :  [%i , %i]'%(list(df['spam class']).count(0),list(df['spam class']).count(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **This shows that ~40% (1813/4601) of the data are classified as SPAM with the remaining ~60% (2788/4601) being non-SPAM. Another observation is that the classifications are actually grouped together, where the SPAM classifications are the FIRST 1813 entries and the latter portion of the dataframe are ALL non-SPAM classifications. This is an interesting finding, as a small training-test split for a cross-validation study can potentially cause classification errors if the an sufficient amount of each group is not represented in the training set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating training-test split function for cross-validation study later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating ANN class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(object):\n",
    "    import time\n",
    "    '''\n",
    "    ------------------------- DESCRIPTION ---------------------------\n",
    "    ANN : artificial neural network using forward+backward propagation\n",
    "    Description: The general flow of this ANN class is as follows:\n",
    "            1. Split data into Training and Test set\n",
    "        On training data, perform:\n",
    "            2. Initialize weights for given number of hidden layers\n",
    "            3. Forward propagate and calc output\n",
    "            4. Back propagate errors\n",
    "                a. reverse network\n",
    "                b. calculate error between output layer\n",
    "                c. calculate error for weights using\n",
    "                    derivative of activation function\n",
    "                d. update weights until input layer reached\n",
    "            CONTINUE UNTIL CONVERGENCE OR ERROR RATE ADEQUATE\n",
    "        On test data, perform:\n",
    "            1. classification decision using training weights\n",
    "    ------------------------------------------------------------------\n",
    "    '''\n",
    "    def __init__(self,data,n_inputs,n_hidden,n_neurons,n_outputs,activation_func,learning_rate,printer=True):\n",
    "        self.data = data\n",
    "        self.n_inputs  = n_inputs\n",
    "        self.n_hidden  = n_hidden\n",
    "        self.n_neurons = n_neurons\n",
    "        self.n_outputs = n_outputs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.activation_func = 'sigmoid'\n",
    "        self.printer = printer\n",
    "        # Checking input value for activation function\n",
    "        if (activation_func!='sigmoid')and(activation_func!='linear')and(activation_func!='softmax'):\n",
    "            print 'Input value:\\t%s'%activation_func\n",
    "            print\n",
    "            print 'CHOOSE CORRECT ACTIVIATION FUNCTION FROM LIST:\\n1.\\tsigmoid\\n2.\\tlinear\\n3.\\tsoftmax'\n",
    "            print\n",
    "        else:\n",
    "            pass\n",
    "      \n",
    "    def test_split(self,data,n):\n",
    "        '''\n",
    "        :param data : { array } feature data\n",
    "        :param n    : { int   } percentage of split in training\n",
    "        '''\n",
    "        data = np.asarray(data)\n",
    "        length_test = int(round(len(data)*(n/100.)))\n",
    "        \n",
    "        # Create random integers between two numbers with no repeats\n",
    "        train_list = random.sample(range(0,len(data)), length_test)\n",
    "        train_list.sort()\n",
    "        test_list = np.arange(0,len(data))\n",
    "        test_list = np.delete(test_list,train_list)\n",
    "        \n",
    "        self.data_train = np.array(data[train_list]) ; #random.shuffle(self.data_train)\n",
    "        self.data_test  = np.array(data[test_list])  ; #random.shuffle(self.data_test)\n",
    "        if self.printer:\n",
    "            print 'CHECK: Original data shape of (%i,%i) and splits shapes:\\n\\ttraining_data:\\t(%i,%i)\\n\\ttest_data:\\t(%i,%i)'\\\n",
    "                    %(data.shape[0],data.shape[1],self.data_train.shape[0],self.data_train.shape[1],\\\n",
    "                      self.data_test.shape[0],self.data_test.shape[1])\n",
    "        return\n",
    "\n",
    "    def initialize(self,number_inputs,number_hidden,number_neurons,number_outputs):\n",
    "        '''\n",
    "        Description : Initialize weights for constructed network. Weight values for the \n",
    "                        hidden layer weights contain a +1 value to account for the bias \n",
    "                        at each layer.\n",
    "        \n",
    "        :param number_inputs  : { int } number of inputs in input layer\n",
    "        :param number_hidden  : { int } number of hidden layers in network\n",
    "        :param number_neurons : { int } number of neurons in hidden layer\n",
    "        :param number_outputs : { int } number of outputs in output layer\n",
    "        '''\n",
    "        network = []\n",
    "        for i in range(number_hidden):\n",
    "            # empty, initialize network\n",
    "            if i==0:\n",
    "                hidden_layer = [{'weights':[random.uniform(0, 1) for i in range(number_inputs + 1)]} for i in range(number_neurons)]\n",
    "                network.append(hidden_layer) \n",
    "            # append after initializations\n",
    "            else:\n",
    "                hidden_layer = [{'weights':[random.uniform(0, 1) for i in range(number_neurons + 1)]} for i in range(number_neurons)]\n",
    "                network.append(hidden_layer)\n",
    "        output_layer = [{'weights':[random.uniform(0, 1) for i in range(number_neurons + 1)]} for i in range(number_outputs)]\n",
    "        network.append(output_layer)\n",
    "        return network\n",
    "    \n",
    "    def activate(self,weights,inputs):\n",
    "        '''\n",
    "        activate : neuron activation function calculated\n",
    "                    by the weighted sum of inputs plus bias.\n",
    "                    Bias is positioned to final value in the list.\n",
    "        '''\n",
    "        activation = weights[-1] # initialize \n",
    "        #print len(weights),len(inputs)\n",
    "        for i in range(len(weights)-1):\n",
    "            activation = activation + weights[i] * inputs[i]\n",
    "        return activation\n",
    "\n",
    "    def activation_function(self,value,values=None):\n",
    "        '''\n",
    "        activation_function : activation function for weight calc\n",
    "        '''\n",
    "        if (self.activation_func=='sigmoid') or (self.activation_func=='logistic sigmoid'):\n",
    "            return (1.0 + np.exp(-value))**-1\n",
    "        if self.activation_func=='linear':\n",
    "            return value\n",
    "        if self.activation_func=='softmax':\n",
    "            return np.exp(value)/np.sum(values)\n",
    "    \n",
    "    def activation_derivative(self,value):\n",
    "        '''\n",
    "        activation_derivative : derivative of activation function\n",
    "        '''\n",
    "        if (self.activation_func=='sigmoid') or (self.activation_func=='logistic sigmoid'):\n",
    "            return value*(1.0 - value)\n",
    "        if self.activation_func=='linear':\n",
    "            return 1.0\n",
    "        if self.activation_func=='softmax':\n",
    "            return value * (1.0 - value)\n",
    "        \n",
    "    def forward(self,network,values):\n",
    "        '''\n",
    "        forward : forward propagation of weights through network\n",
    "        '''\n",
    "        inputs = values\n",
    "        for layer in network:\n",
    "            new_inputs = []\n",
    "            for neuron in layer:\n",
    "                activation = self.activate(neuron['weights'], inputs)\n",
    "                neuron['output'] = self.activation_function(activation)\n",
    "                new_inputs.append(neuron['output'])\n",
    "            inputs = new_inputs\n",
    "        return inputs\n",
    "    \n",
    "    def backward(self,network,known):\n",
    "        '''\n",
    "        backward : backward propagation of errors through network\n",
    "                    calculated with known/given network values\n",
    "        '''\n",
    "        for i in range(len(network))[::-1]:\n",
    "            current_layer = network[i]; errors = []\n",
    "            # initialize errors for output layer\n",
    "            if i == len(network)-1:\n",
    "                for j in range(len(current_layer)):\n",
    "                    neuron = current_layer[j]\n",
    "                    errors.append(self.expected[j] - neuron['output'])\n",
    "            # calculate errors once output layer finished\n",
    "            else:\n",
    "                for j in range(len(current_layer)):\n",
    "                    error = float(0)\n",
    "                    # calculate error between i and i+1 layer\n",
    "                    for neuron in network[i+1]:\n",
    "                        weight = neuron['weights'][j]\n",
    "                        error  = error + weight * neuron['error']\n",
    "                    errors.append(error)\n",
    "            # append dictionary with updated error correction                  \n",
    "            for j in range(len(current_layer)):\n",
    "                neuron = current_layer[j]\n",
    "                neuron['error'] = errors[j] * self.activation_derivative(neuron['output'])\n",
    "        return\n",
    "    \n",
    "\n",
    "    def update_weights(self,network, row, learning_rate):\n",
    "        '''\n",
    "        update_weights : updates weights using stochastic gradient descent\n",
    "        '''\n",
    "        for i in range(len(network)):\n",
    "            inputs = row[:-1]\n",
    "            if i != 0:\n",
    "                inputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "            for neuron in network[i]:\n",
    "                for j in range(len(inputs)):\n",
    "                    neuron['weights'][j] = neuron['weights'][j] + learning_rate * neuron['error'] * inputs[j]\n",
    "                neuron['weights'][-1] = neuron['weights'][-1] + learning_rate * neuron['error']\n",
    "        self.network = network\n",
    "        return network\n",
    "        \n",
    "    def main(self,split,n_epochs):\n",
    "        '''\n",
    "        train : runs ANN with provided network structure and updates weights along the way\n",
    "        '''\n",
    "        self.test_split(self.data,split)\n",
    "        network = self.initialize(self.n_inputs,self.n_hidden,self.n_neurons,self.n_outputs)\n",
    "        self.n_inputs = self.n_inputs-1\n",
    "        #print np.array(network).shape\n",
    "        error_dict = {}\n",
    "        # --- TRAINING NETWORK --- #\n",
    "        start = time.time()\n",
    "        end = 0\n",
    "        checker = True\n",
    "        for epoch in range(n_epochs):\n",
    "            total_error = float(0)\n",
    "            count_pos = 0 ; count_neg = 0\n",
    "            for row in self.data_train:\n",
    "                #print row\n",
    "                outputs = self.forward(network, row)\n",
    "                self.expected = np.zeros(self.n_outputs)\n",
    "                self.expected[row[-1]] = 1\n",
    "                #print self.expected,outputs # *******Test this output comparison********\n",
    "                #print len(self.expected),len(outputs),outputs\n",
    "                for i in range(len(self.expected)):\n",
    "                    ex = list(self.expected)\n",
    "                    out= list(outputs)\n",
    "                    if ex.index(max(ex)) == out.index(max(out)):\n",
    "                        count_pos += 1\n",
    "                    else:\n",
    "                        count_neg += 1\n",
    "                total_error = total_error + sum([(self.expected[i]-outputs[i])**2 for i in range(len(self.expected))])\n",
    "                self.backward(network, self.expected)\n",
    "                self.update_weights(network, row,self.learning_rate)\n",
    "            error_value = float(count_pos)/float(count_pos+count_neg)\n",
    "            if checker:\n",
    "                end = time.time() ; delta = end-start\n",
    "                checker = False\n",
    "            else:\n",
    "                now = time.time() - end\n",
    "                end = end + now ; delta = end-start\n",
    "            if self.printer:\n",
    "                print 'epoch: %i  \\terror: %.4f\\ttime: %.1f   (seconds)'%(epoch+1,total_error,delta)\n",
    "            error_dict[epoch+1] = total_error\n",
    "            \n",
    "        # --- MAKE PREDICTIONS --- #\n",
    "        predicted_values = []\n",
    "        for row in np.array(self.data_test):\n",
    "            outputs = self.forward(self.network, row)\n",
    "            #print row[-1],outputs\n",
    "            predicted_values.append(outputs)\n",
    "\n",
    "        return error_dict,predicted_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running created ANN Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training network on dataset with 57 features and 2 outputs. The number of hidden layers and the number of neurons per hidden layer are variable. I start by ***NORMALIZING*** the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK: Original data shape of (4601,58) and splits shapes:\n",
      "\ttraining_data:\t(2761,58)\n",
      "\ttest_data:\t(1840,58)\n",
      "epoch: 1  \terror: 12.1239\ttime: 0.5   (seconds)\n",
      "epoch: 2  \terror: 0.6099\ttime: 1.0   (seconds)\n",
      "epoch: 3  \terror: 0.3449\ttime: 1.5   (seconds)\n",
      "epoch: 4  \terror: 0.2400\ttime: 2.0   (seconds)\n",
      "epoch: 5  \terror: 0.1837\ttime: 2.5   (seconds)\n",
      "epoch: 6  \terror: 0.1486\ttime: 3.0   (seconds)\n",
      "epoch: 7  \terror: 0.1246\ttime: 3.5   (seconds)\n",
      "epoch: 8  \terror: 0.1072\ttime: 4.0   (seconds)\n",
      "epoch: 9  \terror: 0.0940\ttime: 4.5   (seconds)\n",
      "epoch: 10  \terror: 0.0837\ttime: 5.0   (seconds)\n",
      "epoch: 11  \terror: 0.0754\ttime: 5.5   (seconds)\n",
      "epoch: 12  \terror: 0.0685\ttime: 6.0   (seconds)\n",
      "epoch: 13  \terror: 0.0628\ttime: 6.5   (seconds)\n",
      "epoch: 14  \terror: 0.0580\ttime: 6.9   (seconds)\n",
      "epoch: 15  \terror: 0.0538\ttime: 7.4   (seconds)\n",
      "epoch: 16  \terror: 0.0502\ttime: 7.9   (seconds)\n",
      "epoch: 17  \terror: 0.0470\ttime: 8.4   (seconds)\n",
      "epoch: 18  \terror: 0.0442\ttime: 8.9   (seconds)\n",
      "epoch: 19  \terror: 0.0418\ttime: 9.4   (seconds)\n",
      "epoch: 20  \terror: 0.0395\ttime: 9.9   (seconds)\n",
      "epoch: 21  \terror: 0.0375\ttime: 10.4   (seconds)\n",
      "epoch: 22  \terror: 0.0357\ttime: 10.9   (seconds)\n",
      "epoch: 23  \terror: 0.0341\ttime: 11.4   (seconds)\n",
      "epoch: 24  \terror: 0.0326\ttime: 11.9   (seconds)\n",
      "epoch: 25  \terror: 0.0312\ttime: 12.4   (seconds)\n"
     ]
    }
   ],
   "source": [
    "# Normalizing the dataframe\n",
    "df_norm = (df - df.mean()) / (df.max() - df.min())\n",
    "\n",
    "# ANN(data,n_inputs,n_hidden,n_neurons,n_outputs,activation_func,learning_rate)\n",
    "X = ANN(df_norm, #data\n",
    "        57,  # number of inputs\n",
    "        2,   # number of hidden layers\n",
    "        2,   # number of neurons per hidden layer\n",
    "        2,   # number of outputs (2)\n",
    "        'sigmoid', # activation function\n",
    "        0.5, # learning rate\n",
    "        printer=True)\n",
    "total_error,outputs = X.main(60,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of network: 100.0 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 384x256 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------ Plotting results ------ #\n",
    "x = [i for i in total_error]\n",
    "y = [total_error[i] for i in total_error]\n",
    "fig,ax = plt.subplots(1,1,dpi=64)\n",
    "ax.plot(x,y,'bo--',linewidth=1,markerfacecolor='red',markersize=7,label='Training Error')\n",
    "ax.legend(loc='upper right',fancybox=False,shadow=True)\n",
    "ax.grid(alpha=0.5)\n",
    "ax.set_xlabel('Epoch No.')\n",
    "ax.set_ylabel('Error')\n",
    "if True:\n",
    "    plt.savefig(inPath+'Figures/Training_error.png',dpi=400)\n",
    "\n",
    "# ------ Calculating the prediction accuracy of network ------ #\n",
    "known = np.array([i[-1] for i in X.data_test])\n",
    "known_values = (known - known.mean()) / (known.max() - known.min())\n",
    "outputs = np.asarray(known_values)\n",
    "count_pos = 0 ; count_neg = 0\n",
    "for i in range(len(known_values)):\n",
    "    if (known_values[i]>0.0)and(outputs[i]>0.0):\n",
    "        count_pos+=1\n",
    "    elif (known_values[i]<0.0)and(outputs[i]<0.0):\n",
    "        count_pos+=1\n",
    "    else:\n",
    "        print known_values[i],outputs[i]\n",
    "        count_neg+=1\n",
    "print 'Accuracy of network: %.1f %%'%(float(count_pos)/float(count_pos+count_neg)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
